{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"colab":{"name":"United Airlines.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"7Dr4OI6GDdas"},"source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","from datetime import datetime\n","\n","import dateutil.parser"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8QZgZrUNDdas"},"source":["# dictionary of text dates and links (March 2017 - June 2017)\n","\n","# Febuary 12, 2017\n","url1 = 'https://www.reuters.com/article/us-airlines-united-pilot-idUSKBN15R0RC'\n","\n","# MARCH 7, 2017\n","url2 = 'https://www.reuters.com/article/us-united-airlines-idUSKBN16E2P2'\n","\n","#MARCH 26, 2017\n","url3 = 'https://www.reuters.com/article/us-unitedairlines-leggings-idUSKBN16X13G'\n","\n","# April 7, 2017\n","url4 = 'https://www.reuters.com/article/us-usair-united-idUSTRE6365PN20100408'\n","\n","# April 11, 2017\n","url5 = 'https://www.reuters.com/article/us-ual-passenger-shares-idUSKBN17D1L7'\n","\n","# April 14, 2017\n","url6 = 'https://www.reuters.com/article/us-ual-scorpion-idUSKBN17G1EQ'\n","\n","# APRIL 17, 2017\n","url7 = 'https://www.reuters.com/article/us-ual-passenger-couple-idUSKBN17J05Q'\n","\n","# April 27, 2017\n","url8 = 'https://www.reuters.com/article/us-ual-passenger-idUSKBN17T2WM'\n","\n","# May 2, 2017\n","url9 = 'https://www.reuters.com/article/us-ual-passenger-ceo-idUSKBN17Y1J8'\n","\n","#MAY 4, 2017\n","url10 = 'https://www.reuters.com/article/ual-passenger-idUSL1N1I51WE'\n","\n","\n","#MAY 30, 2017\n","url11 = 'https://www.reuters.com/article/us-united-fine-idUSKBN18Q2EQ'\n","\n","# June 3, 2017\n","url12 = 'https://www.reuters.com/article/us-venezuela-airlines-united-idUSKBN18U0TL'\n","\n","\n","\n","url_dict = {'2017-02-12':url1,\n","            '2017-03-07':url2,\n","            '2017-03-26':url3,\n","            '2017-04-07':url4,\n","            '2017-04-11':url5,\n","            '2017-04-14':url6,\n","            '2017-04-17':url7,\n","            '2017-04-27':url8,\n","            '2017-05-02':url9,\n","            '2017-05-04':url10,\n","            '2017-05-30':url11,\n","            '2017-06-03':url12,\n","           }\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xqgqh9FDDdas"},"source":["# extract info from each website and store it in dataframe\n","df_text = pd.DataFrame(columns = ['Date','Header','Text'])\n","header = []\n","text = []\n","date = []\n","for key in url_dict:\n","    page = requests.get(url_dict[key]).text\n","    soup = BeautifulSoup(page, 'html.parser')\n","    date.append(datetime.strptime(key, '%Y-%m-%d').date())\n","    url_header = soup.find('h1').text\n","    header.append(url_header)\n","    url_text = soup.find('div', class_ ='ArticleBodyWrapper')\n","    url_text = url_text.text\n","    text.append(url_text)\n","df_text['Date']=date\n","df_text['Header']=header\n","df_text['Text']=text\n","\n","# remove the author and \"min read\" sections\n","df_text_temp = [] \n","for text in df_text['Text']:\n","    loc = text.find('(Reuters)')\n","    df_text_temp.append(text[loc+9:])\n","df_text['Text'] = df_text_temp\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q_XGM2UqDdas","outputId":"3d0f84ec-78cc-4e62-eb01-2c491da63962"},"source":["df_text['Date'] = df_text['Date'].apply(lambda x: pd.to_datetime(x))\n","df_text.dtypes"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Date      datetime64[ns]\n","Header            object\n","Text              object\n","dtype: object"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"L-SPszp_Ddat","outputId":"f716f727-31a4-49c2-c328-3b90738a7f5a"},"source":["# import stock data of netflix\n","df_stock = pd.read_csv('UAL.csv', header=0)\n","\n","df_stock['Date']=df_stock['Date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))\n","\n","\n","df_stock = df_stock.drop(['High','Low','Close','Adj Close'], axis=1)\n","df_stock.dtypes"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Date      datetime64[ns]\n","Open             float64\n","Volume             int64\n","dtype: object"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"iH09drfiDdat"},"source":["# Merge two dataframes\n","df = pd.merge(df_text, df_stock, how='inner', on='Date')\n","df = df.sort_values('Date')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i2_UJYBGDdat","outputId":"6322a9f3-9189-413b-f045-f1fe3772a345"},"source":["# show % change in stock price after news article publish\n","pct_stock = df['Open'].pct_change()*100\n","df['% Change in Stock Price'] = pct_stock\n","pct_volume = df['Volume'].pct_change()*100\n","df['% Change in Volume'] = pct_volume\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date</th>\n","      <th>Header</th>\n","      <th>Text</th>\n","      <th>Open</th>\n","      <th>Volume</th>\n","      <th>% Change in Stock Price</th>\n","      <th>% Change in Volume</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2017-03-07</td>\n","      <td>United looking at second-hand aircraft, rules ...</td>\n","      <td>- United Continental Holdings UAKL.N is inter...</td>\n","      <td>72.690002</td>\n","      <td>3764000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2017-04-07</td>\n","      <td>UAL pilots attack U.S. Airways merger prospect</td>\n","      <td>- United Airlines' pilots union lashed out ag...</td>\n","      <td>69.970001</td>\n","      <td>2471100</td>\n","      <td>-3.741919</td>\n","      <td>-34.349097</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2017-04-11</td>\n","      <td>United Airlines faces mounting pressure over h...</td>\n","      <td>- United Airlines UAL.N and its chief executi...</td>\n","      <td>70.150002</td>\n","      <td>17696500</td>\n","      <td>0.257255</td>\n","      <td>616.138562</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2017-04-17</td>\n","      <td>United Air removes couple traveling to wedding...</td>\n","      <td>- An engaged couple were removed from a Unite...</td>\n","      <td>69.510002</td>\n","      <td>4761900</td>\n","      <td>-0.912331</td>\n","      <td>-73.091289</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2017-04-27</td>\n","      <td>United Airlines reaches settlement with passen...</td>\n","      <td>- United Airlines UAL.N and the passenger who...</td>\n","      <td>69.769997</td>\n","      <td>5512200</td>\n","      <td>0.374040</td>\n","      <td>15.756316</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        Date                                             Header  \\\n","0 2017-03-07  United looking at second-hand aircraft, rules ...   \n","1 2017-04-07     UAL pilots attack U.S. Airways merger prospect   \n","2 2017-04-11  United Airlines faces mounting pressure over h...   \n","3 2017-04-17  United Air removes couple traveling to wedding...   \n","4 2017-04-27  United Airlines reaches settlement with passen...   \n","\n","                                                Text       Open    Volume  \\\n","0   - United Continental Holdings UAKL.N is inter...  72.690002   3764000   \n","1   - United Airlines' pilots union lashed out ag...  69.970001   2471100   \n","2   - United Airlines UAL.N and its chief executi...  70.150002  17696500   \n","3   - An engaged couple were removed from a Unite...  69.510002   4761900   \n","4   - United Airlines UAL.N and the passenger who...  69.769997   5512200   \n","\n","   % Change in Stock Price  % Change in Volume  \n","0                      NaN                 NaN  \n","1                -3.741919          -34.349097  \n","2                 0.257255          616.138562  \n","3                -0.912331          -73.091289  \n","4                 0.374040           15.756316  "]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"tIJwNIEADdat"},"source":["# Processing the text\n"]},{"cell_type":"markdown","metadata":{"id":"K3xPxXfKDdat"},"source":["## import spacy libraries\n","import spacy\n","import en_core_web_sm\n","from  spacy.lang.en.stop_words import STOP_WORDS\n","nlp = spacy.load('en_core_web_sm')"]},{"cell_type":"code","metadata":{"id":"0UHQPteUDdat"},"source":["# import spacy libraries\n","import spacy\n","import en_core_web_sm\n","from  spacy.lang.en.stop_words import STOP_WORDS\n","nlp = spacy.load('en_core_web_sm')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lLlOVsMxDdat"},"source":["\n","text_nlp = nlp(df['Text'][1]) \n","# Remove stop words\n","text_nlp_clean = [word for word in text_nlp if word.is_stop == False]\n","# Lemmatize words\n","text_nlp_clean = [word.lemma_ for word in text_nlp_clean]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OoS2AO88Ddat","outputId":"bf9a436a-1222-46ef-c10f-389ba2bf3f5a"},"source":["text_clean = []\n","for ind, row in df.iterrows():\n","    \n","    # lower casing\n","    text_lower = row['Text'].lower()\n","    \n","    # tokenization\n","    text_nlp = nlp(row['Text']) \n","    \n","    # remove punctuation and empty space\n","    text_nlp_clean = [word for word in text_nlp if not word.is_punct | word.is_space]\n","    \n","    # Remove stop words\n","    text_nlp_clean = [word for word in text_nlp_clean if word.is_stop == False]\n","    \n","    # Lemmatize tokens\n","    text_nlp_clean = [word.lemma_ for word in text_nlp_clean]\n","    \n","    # add preprocessed text to list\n","    text_clean.append(text_nlp_clean)\n","\n","# turn list of words to string\n","def to_string(list1):\n","    sentence = \"\"\n","    \n","    \n","    # traverse in the string   \n","    for word in list1:  \n","        sentence += str(word) \n","    \n","    # return string   \n","    return sentence\n","\n","# turn list of strings to string\n","to_string = []\n","for text in text_clean:\n","    to_string.append(' '.join(text))\n","\n","\n","df['Text (clean)'] = to_string\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date</th>\n","      <th>Header</th>\n","      <th>Text</th>\n","      <th>Open</th>\n","      <th>Volume</th>\n","      <th>% Change in Stock Price</th>\n","      <th>% Change in Volume</th>\n","      <th>Text (clean)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2017-03-07</td>\n","      <td>United looking at second-hand aircraft, rules ...</td>\n","      <td>- United Continental Holdings UAKL.N is inter...</td>\n","      <td>72.690002</td>\n","      <td>3764000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>United Continental Holdings UAKL.N interested ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2017-04-07</td>\n","      <td>UAL pilots attack U.S. Airways merger prospect</td>\n","      <td>- United Airlines' pilots union lashed out ag...</td>\n","      <td>69.970001</td>\n","      <td>2471100</td>\n","      <td>-3.741919</td>\n","      <td>-34.349097</td>\n","      <td>United Airlines pilot union lash effort merge ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2017-04-11</td>\n","      <td>United Airlines faces mounting pressure over h...</td>\n","      <td>- United Airlines UAL.N and its chief executi...</td>\n","      <td>70.150002</td>\n","      <td>17696500</td>\n","      <td>0.257255</td>\n","      <td>616.138562</td>\n","      <td>United Airlines UAL.N chief executive face mou...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2017-04-17</td>\n","      <td>United Air removes couple traveling to wedding...</td>\n","      <td>- An engaged couple were removed from a Unite...</td>\n","      <td>69.510002</td>\n","      <td>4761900</td>\n","      <td>-0.912331</td>\n","      <td>-73.091289</td>\n","      <td>engage couple remove United Airlines flight Co...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2017-04-27</td>\n","      <td>United Airlines reaches settlement with passen...</td>\n","      <td>- United Airlines UAL.N and the passenger who...</td>\n","      <td>69.769997</td>\n","      <td>5512200</td>\n","      <td>0.374040</td>\n","      <td>15.756316</td>\n","      <td>United Airlines UAL.N passenger drag Chicago f...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        Date                                             Header  \\\n","0 2017-03-07  United looking at second-hand aircraft, rules ...   \n","1 2017-04-07     UAL pilots attack U.S. Airways merger prospect   \n","2 2017-04-11  United Airlines faces mounting pressure over h...   \n","3 2017-04-17  United Air removes couple traveling to wedding...   \n","4 2017-04-27  United Airlines reaches settlement with passen...   \n","\n","                                                Text       Open    Volume  \\\n","0   - United Continental Holdings UAKL.N is inter...  72.690002   3764000   \n","1   - United Airlines' pilots union lashed out ag...  69.970001   2471100   \n","2   - United Airlines UAL.N and its chief executi...  70.150002  17696500   \n","3   - An engaged couple were removed from a Unite...  69.510002   4761900   \n","4   - United Airlines UAL.N and the passenger who...  69.769997   5512200   \n","\n","   % Change in Stock Price  % Change in Volume  \\\n","0                      NaN                 NaN   \n","1                -3.741919          -34.349097   \n","2                 0.257255          616.138562   \n","3                -0.912331          -73.091289   \n","4                 0.374040           15.756316   \n","\n","                                        Text (clean)  \n","0  United Continental Holdings UAKL.N interested ...  \n","1  United Airlines pilot union lash effort merge ...  \n","2  United Airlines UAL.N chief executive face mou...  \n","3  engage couple remove United Airlines flight Co...  \n","4  United Airlines UAL.N passenger drag Chicago f...  "]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"7Q8ZXUBzDdat"},"source":["# Using a Pretrained Model "]},{"cell_type":"code","metadata":{"id":"u36DHZGtDdat"},"source":["from nltk.sentiment import SentimentIntensityAnalyzer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"go0fwZHoDdat"},"source":["# a function to return sentiment score\n","def polarity_score(text):\n","    sid = SentimentIntensityAnalyzer()\n","    return sid.polarity_scores(text)['compound']\n","\n","vader_score = []\n","for text in df['Text (clean)']:\n","    score = polarity_score(text)\n","    vader_score.append(score)\n","\n","df['Vader Sentiment Score'] = vader_score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VAAANMmPDdat","outputId":"f6747501-442b-411b-9098-8a6c99c3eb88"},"source":["df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date</th>\n","      <th>Header</th>\n","      <th>Text</th>\n","      <th>Open</th>\n","      <th>Volume</th>\n","      <th>% Change in Stock Price</th>\n","      <th>% Change in Volume</th>\n","      <th>Text (clean)</th>\n","      <th>Vader Sentiment Score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2017-03-07</td>\n","      <td>United looking at second-hand aircraft, rules ...</td>\n","      <td>- United Continental Holdings UAKL.N is inter...</td>\n","      <td>72.690002</td>\n","      <td>3764000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>United Continental Holdings UAKL.N interested ...</td>\n","      <td>0.9485</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2017-04-07</td>\n","      <td>UAL pilots attack U.S. Airways merger prospect</td>\n","      <td>- United Airlines' pilots union lashed out ag...</td>\n","      <td>69.970001</td>\n","      <td>2471100</td>\n","      <td>-3.741919</td>\n","      <td>-34.349097</td>\n","      <td>United Airlines pilot union lash effort merge ...</td>\n","      <td>0.9981</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2017-04-11</td>\n","      <td>United Airlines faces mounting pressure over h...</td>\n","      <td>- United Airlines UAL.N and its chief executi...</td>\n","      <td>70.150002</td>\n","      <td>17696500</td>\n","      <td>0.257255</td>\n","      <td>616.138562</td>\n","      <td>United Airlines UAL.N chief executive face mou...</td>\n","      <td>0.9877</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2017-04-17</td>\n","      <td>United Air removes couple traveling to wedding...</td>\n","      <td>- An engaged couple were removed from a Unite...</td>\n","      <td>69.510002</td>\n","      <td>4761900</td>\n","      <td>-0.912331</td>\n","      <td>-73.091289</td>\n","      <td>engage couple remove United Airlines flight Co...</td>\n","      <td>0.9501</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2017-04-27</td>\n","      <td>United Airlines reaches settlement with passen...</td>\n","      <td>- United Airlines UAL.N and the passenger who...</td>\n","      <td>69.769997</td>\n","      <td>5512200</td>\n","      <td>0.374040</td>\n","      <td>15.756316</td>\n","      <td>United Airlines UAL.N passenger drag Chicago f...</td>\n","      <td>0.9136</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        Date                                             Header  \\\n","0 2017-03-07  United looking at second-hand aircraft, rules ...   \n","1 2017-04-07     UAL pilots attack U.S. Airways merger prospect   \n","2 2017-04-11  United Airlines faces mounting pressure over h...   \n","3 2017-04-17  United Air removes couple traveling to wedding...   \n","4 2017-04-27  United Airlines reaches settlement with passen...   \n","\n","                                                Text       Open    Volume  \\\n","0   - United Continental Holdings UAKL.N is inter...  72.690002   3764000   \n","1   - United Airlines' pilots union lashed out ag...  69.970001   2471100   \n","2   - United Airlines UAL.N and its chief executi...  70.150002  17696500   \n","3   - An engaged couple were removed from a Unite...  69.510002   4761900   \n","4   - United Airlines UAL.N and the passenger who...  69.769997   5512200   \n","\n","   % Change in Stock Price  % Change in Volume  \\\n","0                      NaN                 NaN   \n","1                -3.741919          -34.349097   \n","2                 0.257255          616.138562   \n","3                -0.912331          -73.091289   \n","4                 0.374040           15.756316   \n","\n","                                        Text (clean)  Vader Sentiment Score  \n","0  United Continental Holdings UAKL.N interested ...                 0.9485  \n","1  United Airlines pilot union lash effort merge ...                 0.9981  \n","2  United Airlines UAL.N chief executive face mou...                 0.9877  \n","3  engage couple remove United Airlines flight Co...                 0.9501  \n","4  United Airlines UAL.N passenger drag Chicago f...                 0.9136  "]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"n4JWxE78Ddat"},"source":["## Sentiment Analysis"]},{"cell_type":"code","metadata":{"id":"6w4w6eY3Ddat"},"source":["# run this cell to import nltk\n","import nltk\n","from os import getcwd\n","import numpy as np\n","import pandas as pd\n","from nltk.corpus import twitter_samples \n","from utils import process_tweet, build_freqs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D2vYa7ZMDdat","outputId":"ff24745e-2b00-4740-d158-b1ec548a29db"},"source":["nltk.download('twitter_samples')\n","nltk.download('stopwords')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package twitter_samples to\n","[nltk_data]     C:\\Users\\aashi\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package twitter_samples is already up-to-date!\n","[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\aashi\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"ffCWEx_3Ddau"},"source":["\n","# select the set of positive and negative tweets\n","all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n","all_negative_tweets = twitter_samples.strings('negative_tweets.json')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-iN_wDGWDdau"},"source":["# split the data into two pieces (80-20), one for training and one for testing (validation set)  \n","test_pos = all_positive_tweets[4000:]\n","train_pos = all_positive_tweets[:4000]\n","test_neg = all_negative_tweets[4000:]\n","train_neg = all_negative_tweets[:4000]\n","\n","train_x = train_pos + train_neg \n","test_x = test_pos + test_neg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v_m2WPlXDdau"},"source":["# combine positive and negative labels\n","train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n","test_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qljZ_zyMDdau","outputId":"80b8ace8-f16b-4185-ade8-cda034e42153"},"source":["# Print the shape train and test sets\n","print(\"train_y.shape = \" + str(train_y.shape))\n","print(\"test_y.shape = \" + str(test_y.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["train_y.shape = (8000, 1)\n","test_y.shape = (2000, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YgmamA5yDdau","outputId":"0c40a7f9-dccc-4c38-d29c-c3524a0ba194"},"source":["# create frequency dictionary\n","freqs = build_freqs(train_x, train_y)\n","\n","# check the output\n","print(\"type(freqs) = \" + str(type(freqs)))\n","print(\"len(freqs) = \" + str(len(freqs.keys())))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["type(freqs) = <class 'dict'>\n","len(freqs) = 11340\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dZfcBZ_fDdau"},"source":["# UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n","def extract_features(tweet, freqs):\n","    '''\n","    Input: \n","        tweet: a list of words for one tweet\n","        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n","    Output: \n","        x: a feature vector of dimension (1,3)\n","    '''\n","    # process_tweet tokenizes, stems, and removes stopwords\n","    word_l = process_tweet(tweet)\n","    \n","    # 3 elements in the form of a 1 x 3 vector\n","    x = np.zeros((1, 3)) \n","    \n","    #bias term is set to 1\n","    x[0,0] = 1 \n","    \n","    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n","    \n","    # loop through each word in the list of words\n","    for word in word_l:\n","        \n","        # increment the word count for the positive label 1\n","        \n","        x[0,1] += freqs.get((word,1),0)\n","        \n","        # increment the word count for the negative label 0\n","        x[0,2] += freqs.get((word,0),0)\n","        \n","    ### END CODE HERE ###\n","    assert(x.shape == (1, 3))\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uuP9kCTYDdau"},"source":["# collect the features 'x' and stack them into a matrix 'X'\n","X = np.zeros((len(train_x), 3))\n","for i in range(len(train_x)):\n","    X[i, :]= extract_features(train_x[i], freqs)\n","\n","# training labels corresponding to X\n","Y = train_y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7DQI0XyXDdau","outputId":"a8ff2fdc-928e-4628-814b-69d0689fc990"},"source":["Y.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8000, 1)"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"1J9qcsPnDdau"},"source":["from sklearn.model_selection import GridSearchCV\n","from sklearn.linear_model import LogisticRegression\n","from sklearn import svm\n","from sklearn.pipeline import Pipeline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k7oTaYsZDdau"},"source":["### SVM Parameters"]},{"cell_type":"code","metadata":{"id":"qIK8HcKsDdau"},"source":["param_grid = {'C': [0.0001, 0.001, 0.01, 0.1, 1]}  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gmeUCZJ9Ddau","outputId":"092b7b2b-3294-44fc-f92e-14c456a9c8b3"},"source":["# Fitting Logistic Regression to the Training set\n","from sklearn.linear_model import LogisticRegression\n","classifier = LogisticRegression(random_state = 0)\n","classifier.fit(X, Y)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["C:\\Users\\aashi\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  return f(**kwargs)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["LogisticRegression(random_state=0)"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"769QIx9uDdau"},"source":["\n","# UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n","def predict_tweet(tweet, freqs):\n","    '''\n","    Input: \n","        tweet: a string\n","        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n","        theta: (3,1) vector of weights\n","    Output: \n","        y_pred: the probability of a tweet being positive or negative\n","    '''\n","    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n","    \n","    # extract the features of the tweet and store it into x\n","    x = extract_features(tweet,freqs)\n","    \n","    # make the prediction using x and theta\n","    y_pred = classifier.predict(x)\n","    \n","    ### END CODE HERE ###\n","    \n","    return y_pred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ftumYLvdDdau"},"source":["# UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n","def predict_tweet_prob(tweet, freqs):\n","    '''\n","    Input: \n","        tweet: a string\n","        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n","        theta: (3,1) vector of weights\n","    Output: \n","        y_pred: the probability of a tweet being positive or negative\n","    '''\n","    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n","    \n","    # extract the features of the tweet and store it into x\n","    x = extract_features(tweet,freqs)\n","    \n","    # make the prediction using x and theta\n","    y_pred = classifier.predict_proba(x)\n","    \n","    ### END CODE HERE ###\n","    \n","    return y_pred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1yoG7ljmDdau","outputId":"cd1a9d11-a455-47a3-e90b-ced3d047132a"},"source":["\n","my_tweet = 'The plot was terrible and I was sad until the ending!'\n","predict_tweet(my_tweet, freqs)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.])"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"markdown","metadata":{"id":"GbQfcoedDgWy"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"9b3FGYquGJt2"},"source":["#START OF DEEP LEARNING"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o2ysV6jADflZ","executionInfo":{"status":"ok","timestamp":1607040836213,"user_tz":300,"elapsed":8386,"user":{"displayName":"Fahim Ishrak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggezk-2c-RhJe7s98IHcOwr_FzjJAx4Bw_3AS5xPt8=s64","userId":"00540352956280049870"}},"outputId":"147c77d0-961b-420a-9f86-8327aa71fcd8"},"source":["import sklearn\n","import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_colwidth', -1)\n","import sklearn\n","import sklearn.ensemble\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","import sklearn.metrics\n","import tensorflow as tf\n","from scipy.special import softmax\n","import os\n","import numpy as np\n","import pandas as pd\n","import json\n","import torch\n","import torch.nn as nn\n","import nltk\n","from tqdm import tqdm\n","import spacy\n","import torch\n","import torchtext\n","import torchtext.data\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from scipy.special import softmax\n","from torchtext.vocab import Vocab\n","from nltk.corpus import twitter_samples \n","\n","nlp = spacy.load('en')\n","nltk.download('punkt')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n","  after removing the cwd from sys.path.\n"],"name":"stderr"},{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"rXcDVFHeDhg8"},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","torch.manual_seed(42)\n","np.random.seed(42)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bRV7w-rvDhqP"},"source":["# %% ----------------------------------- Hyper Parameters --------------------------------------------------------------\n","class Args:\n","    def __init__(self):\n","        self.seq_len = \"get_max_from_data\"\n","        self.embedding_dim = 50\n","        self.n_epochs = 10\n","        self.lr = 1e-2\n","        self.batch_size = 512\n","        self.train = True\n","        self.save_model = True\n","\n","\n","args = Args()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jWnuKaQDDhyV"},"source":["# %% ----------------------------------- Helper Functions --------------------------------------------------------------\n","def acc(x, y, return_labels=False):\n","    with torch.no_grad():\n","        logits = torch.empty(len(x), 2)\n","        for batch in range(len(x) // args.batch_size + 1):\n","            inds = slice(batch * args.batch_size, (batch + 1) * args.batch_size)\n","            logits[inds] = model(x[inds])\n","        pred_labels = np.argmax(logits.cpu().numpy(), axis=1)\n","    if return_labels:\n","        return pred_labels\n","    else:\n","        return 100*accuracy_score(y.cpu().numpy(), pred_labels)\n","\n","\n","def extract_vocab_dict_and_msl(sentences_train, sentences_dev):\n","    \"\"\" Tokenizes all the sentences and gets a dictionary of unique tokens and also the maximum sequence length \"\"\"\n","    tokens, ms_len = [], 0\n","    for sentence in list(sentences_train) + list(sentences_dev):\n","        tokens_in_sentence = nltk.word_tokenize(sentence)\n","        if ms_len < len(tokens_in_sentence):\n","            ms_len = len(tokens_in_sentence)\n","        tokens += tokens_in_sentence\n","    token_vocab = {key: i for key, i in zip(set(tokens), range(1, len(set(tokens))+1))}\n","    if len(np.unique(list(token_vocab.values()))) != len(token_vocab):\n","        \"There are some rep words...\"\n","    return token_vocab, ms_len\n","\n","\n","def convert_to_ids(raw_sentences, vocab_dict, pad_to):\n","    \"\"\" Takes an NumPy array of raw text sentences and converts to a sequence of token ids \"\"\"\n","    x = np.empty((len(raw_sentences), pad_to))\n","    for idx, sentence in enumerate(raw_sentences):\n","        word_ids = []\n","        for token in nltk.word_tokenize(sentence):\n","            try:\n","                word_ids.append(vocab_dict[token])\n","            except:\n","                word_ids.append(vocab_dict[token])\n","        if pad_to < len(word_ids):\n","            x[idx] = word_ids[:pad_to]\n","        else:\n","            x[idx] = word_ids + [0] * (pad_to - len(word_ids))\n","    return x\n","\n","\n","def get_glove_embeddings(vocab_dict):\n","    with open(\"glove.6B.50d.txt\", \"r\") as s:\n","        glove = s.read()\n","    embeddings_dict = {}\n","    for line in glove.split(\"\\n\")[:-1]:\n","        text = line.split()\n","        if text[0] in vocab_dict:\n","            embeddings_dict[vocab_dict[text[0]]] = torch.from_numpy(np.array(text[1:], dtype=\"float32\"))\n","    return embeddings_dict\n","\n","\n","def get_glove_table(vocab_dict, glove_dict):\n","    lookup_table = torch.empty((len(vocab_dict)+2, 50))\n","    for token_id in sorted(vocab_dict.values()):\n","        if token_id in glove_dict:\n","            lookup_table[token_id] = glove_dict[token_id]\n","        else:\n","            lookup_table[token_id] = torch.zeros((1, 50))  # For unknown tokens\n","    lookup_table[0] = torch.zeros((1, 50))\n","    return lookup_table\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wBpei6jODiHg"},"source":["data_train = pd.read_csv(\"original_data/train.tsv\", sep=\"\\t\")\n","x_train_raw, y_train = data_train[\"sentence\"].values, torch.LongTensor(data_train[\"label\"].values).to(device)\n","data_dev = pd.read_csv(\"original_data/dev.tsv\", sep=\"\\t\")\n","x_dev_raw, y_dev = data_dev[\"sentence\"].values, torch.LongTensor(data_dev[\"label\"].values).to(device)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J7cwegREDh1i"},"source":["# %% -------------------------------------- Data Prep ------------------------------------------------------------------\n","try:\n","    with open(\"example_prep_data/vocab_dict.json\", \"r\") as s:\n","        token_ids = json.load(s)\n","    msl = np.load(\"example_prep_data/max_sequence_length.npy\").item()\n","except:\n","    print(\"Tokenizing all the examples to get a vocab dict and the maximum sequence length...\")\n","    token_ids, msl = extract_vocab_dict_and_msl(x_train_raw, x_dev_raw)\n","    os.mkdir(\"example_prep_data\")\n","    with open(\"example_prep_data/vocab_dict.json\", \"w\") as s:\n","        json.dump(token_ids, s)\n","    np.save(\"example_prep_data/max_sequence_length.npy\", np.array([msl]))\n","if args.seq_len == \"get_max_from_data\":\n","    args.seq_len = msl\n","\n","glove_embeddings = get_glove_embeddings(token_ids)\n","\n","try:\n","    x_train = np.load(\"example_prep_data/prep_train_len{}.npy\".format(args.seq_len))\n","    x_dev = np.load(\"example_prep_data/prep_dev_len{}.npy\".format(args.seq_len))\n","except:\n","    print(\"Converting all the sentences to sequences of token ids...\")\n","    x_train = convert_to_ids(x_train_raw, token_ids, args.seq_len)\n","    np.save(\"example_prep_data/prep_train_len{}.npy\".format(args.seq_len), x_train)\n","    x_dev = convert_to_ids(x_dev_raw, token_ids, args.seq_len)\n","    np.save(\"example_prep_data/prep_dev_len{}.npy\".format(args.seq_len), x_dev)\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PjMGiikrDhul"},"source":["x_train, x_dev = torch.LongTensor(x_train).to(device), torch.LongTensor(x_dev).to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Zk6bwAlGmI_"},"source":["# %% -------------------------------------- CNN Class ------------------------------------------------------------------\n","class CNN(nn.Module):\n","    def __init__(self, vocab_size):\n","        super(CNN, self).__init__()\n","\n","        self.embedding = nn.Embedding(vocab_size + 2, args.embedding_dim)\n","\n","        self.conv1 = nn.Conv1d(args.embedding_dim, args.embedding_dim, 9)\n","        self.convnorm1 = nn.BatchNorm1d(args.embedding_dim)\n","        self.pool1 = nn.MaxPool1d(2)\n","\n","        self.conv2 = nn.Conv1d(args.embedding_dim, args.embedding_dim, 9)\n","        self.convnorm2 = nn.BatchNorm1d(args.embedding_dim)\n","        self.pool2 = nn.MaxPool1d(2)\n","\n","        self.conv3 = nn.Conv1d(args.embedding_dim, args.embedding_dim, 7)\n","        self.linear = nn.Linear(args.embedding_dim, 2)\n","        self.act = torch.relu\n","\n","    def forward(self, x):\n","        # nn.Conv1d operates on the columns, each embedding dimension is considered as one channel\n","        x = self.embedding(x).permute(0, 2, 1)\n","        x = self.pool1(self.convnorm1(self.act(self.conv1(x))))\n","        x = self.pool2(self.convnorm2(self.act(self.conv2(x))))\n","        return self.linear(self.act(self.conv3(x)).reshape(-1, args.embedding_dim))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ckx9tsZyDhkp"},"source":["# %% -------------------------------------- Training Prep ----------------------------------------------------------\n","model = CNN(len(token_ids)).to(device)\n","look_up_table = get_glove_table(token_ids, glove_embeddings)\n","model.embedding.weight.data.copy_(look_up_table)\n","optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n","criterion = nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wb0tiRRYDg9r"},"source":["# %% -------------------------------------- Training Loop ----------------------------------------------------------\n","labels_ditrib = torch.unique(y_dev, return_counts=True)\n","print(\"The no information rate is {:.2f}\".format(100*labels_ditrib[1].max().item()/len(y_dev)))\n","if args.train:\n","    acc_dev_best = 0\n","    print(\"Starting training loop...\")\n","    for epoch in range(args.n_epochs):\n","\n","        loss_train, train_steps = 0, 0\n","        model.train()\n","        total = len(x_train) // args.batch_size + 1  # Initiates a progress bar that will be updated for each batch\n","        with tqdm(total=total, desc=\"Epoch {}\".format(epoch)) as pbar:  # \"Epoch\" will be updated for each epoch\n","            for batch in range(len(x_train)//args.batch_size + 1):\n","                inds = slice(batch*args.batch_size, (batch+1)*args.batch_size)\n","                optimizer.zero_grad()\n","                logits = model(x_train[inds])\n","                loss = criterion(logits, y_train[inds])\n","                loss.backward()\n","                optimizer.step()\n","                loss_train += loss.item()\n","                train_steps += 1\n","                pbar.update(1)  # Updates the progress and the training loss\n","                pbar.set_postfix_str(\"Training Loss: {:.5f}\".format(loss_train / train_steps))\n","\n","        model.eval()\n","        with torch.no_grad():\n","            y_dev_pred = model(x_dev)\n","            loss = criterion(y_dev_pred, y_dev)\n","            loss_test = loss.item()\n","\n","        acc_dev = acc(x_dev, y_dev)\n","        print(\"Epoch {} | Train Loss {:.5f}, Train Acc {:.2f} - Test Loss {:.5f}, Test Acc {:.2f}\".format(\n","            epoch, loss_train/train_steps, acc(x_train, y_train), loss_test, acc_dev))\n","\n","        if acc_dev > acc_dev_best and args.save_model:\n","            torch.save(model.state_dict(), \"cnn_sentiment.pt\")\n","            print(\"The model has been saved!\")\n","            acc_dev_best = acc_dev"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ELo3KTaYGuZl"},"source":["# Test of Deep Learning"]},{"cell_type":"code","metadata":{"id":"mnKEMV0PGrqx"},"source":["x = None\n","for i in range(10):\n","    test = convert_to_ids([x_train_raw[i]], token_ids, args.seq_len)\n","    test = torch.LongTensor(test).to(device)\n","    pred = model(test).cpu().detach().numpy()[0]\n","    x = softmax(pred)\n","    print(softmax(pred),y_train[i])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Muy_HSGGr3U"},"source":["\n","x = None\n","deep_learning_sentiment_prob = []\n","\n","for i in df.iloc[:,2]:\n","    test = convert_to_ids([i], token_ids, args.seq_len)\n","    test = torch.LongTensor(test).to(device)\n","    pred = model(test).cpu().detach().numpy()[0]\n","    x = softmax(pred)\n","    sentiment_prob.append(x[1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kbxNQeb7GrfE"},"source":["df['deep_learning_sentiment_prob'] = sentiment_prob"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u1eMsRcWGz_y"},"source":["#END OF DEEP LEARNING"]},{"cell_type":"markdown","metadata":{"id":"E5itPFkfDdau"},"source":["# Testing the Model "]},{"cell_type":"code","metadata":{"id":"4ZuZ70ERDdau"},"source":["sentiment = []\n","sentiment_prob = []\n","for i in df.iloc[:,2]:\n","    sentiment.append(predict_tweet(i, freqs)[0])\n","    sentiment_prob.append(predict_tweet_prob(i, freqs)[0][1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YZV1N4W4Ddau","outputId":"a44f4b0b-dd25-4a57-d17c-2491efc66aae"},"source":["sentiment\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"id":"Z_7uWuU-Ddau","outputId":"35a42409-a0b6-4551-c4a5-b83ee0d0dc7a"},"source":["sentiment_prob"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.6938569763837213,\n"," 0.000992856711037133,\n"," 0.016640031758956002,\n"," 0.10050501782597547,\n"," 0.003088541074744996,\n"," 5.593078354866826e-05,\n"," 0.03852008349259754,\n"," 0.5557759528050944]"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"code","metadata":{"id":"bT1USMtADdau","outputId":"994c0124-4d77-43f1-dd39-242abad336f9"},"source":["df['sentiment'] = sentiment\n","df['sentiment_prob'] = sentiment_prob\n","df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date</th>\n","      <th>Header</th>\n","      <th>Text</th>\n","      <th>Open</th>\n","      <th>Volume</th>\n","      <th>% Change in Stock Price</th>\n","      <th>% Change in Volume</th>\n","      <th>Text (clean)</th>\n","      <th>Vader Sentiment Score</th>\n","      <th>sentiment</th>\n","      <th>sentiment_prob</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2017-03-07</td>\n","      <td>United looking at second-hand aircraft, rules ...</td>\n","      <td>- United Continental Holdings UAKL.N is inter...</td>\n","      <td>72.690002</td>\n","      <td>3764000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>United Continental Holdings UAKL.N interested ...</td>\n","      <td>0.9485</td>\n","      <td>1.0</td>\n","      <td>0.693857</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2017-04-07</td>\n","      <td>UAL pilots attack U.S. Airways merger prospect</td>\n","      <td>- United Airlines' pilots union lashed out ag...</td>\n","      <td>69.970001</td>\n","      <td>2471100</td>\n","      <td>-3.741919</td>\n","      <td>-34.349097</td>\n","      <td>United Airlines pilot union lash effort merge ...</td>\n","      <td>0.9981</td>\n","      <td>0.0</td>\n","      <td>0.000993</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2017-04-11</td>\n","      <td>United Airlines faces mounting pressure over h...</td>\n","      <td>- United Airlines UAL.N and its chief executi...</td>\n","      <td>70.150002</td>\n","      <td>17696500</td>\n","      <td>0.257255</td>\n","      <td>616.138562</td>\n","      <td>United Airlines UAL.N chief executive face mou...</td>\n","      <td>0.9877</td>\n","      <td>0.0</td>\n","      <td>0.016640</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2017-04-17</td>\n","      <td>United Air removes couple traveling to wedding...</td>\n","      <td>- An engaged couple were removed from a Unite...</td>\n","      <td>69.510002</td>\n","      <td>4761900</td>\n","      <td>-0.912331</td>\n","      <td>-73.091289</td>\n","      <td>engage couple remove United Airlines flight Co...</td>\n","      <td>0.9501</td>\n","      <td>0.0</td>\n","      <td>0.100505</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2017-04-27</td>\n","      <td>United Airlines reaches settlement with passen...</td>\n","      <td>- United Airlines UAL.N and the passenger who...</td>\n","      <td>69.769997</td>\n","      <td>5512200</td>\n","      <td>0.374040</td>\n","      <td>15.756316</td>\n","      <td>United Airlines UAL.N passenger drag Chicago f...</td>\n","      <td>0.9136</td>\n","      <td>0.0</td>\n","      <td>0.003089</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2017-05-02</td>\n","      <td>U.S. lawmakers grill airline executives after ...</td>\n","      <td>- U.S. lawmakers threatened United Airlines U...</td>\n","      <td>70.430000</td>\n","      <td>5434700</td>\n","      <td>0.945970</td>\n","      <td>-1.405972</td>\n","      <td>U.S. lawmaker threaten United Airlines UAL.N c...</td>\n","      <td>0.9460</td>\n","      <td>0.0</td>\n","      <td>0.000056</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>2017-05-04</td>\n","      <td>United Air to face second congressional grilli...</td>\n","      <td>- United Airlines will be back in the hot sea...</td>\n","      <td>74.559998</td>\n","      <td>2886300</td>\n","      <td>5.863976</td>\n","      <td>-46.891273</td>\n","      <td>United Airlines hot seat Thursday U.S. Congres...</td>\n","      <td>0.9921</td>\n","      <td>0.0</td>\n","      <td>0.038520</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>2017-05-30</td>\n","      <td>U.S. proposes fining United $435,000 over 2014...</td>\n","      <td>- The U.S. Federal Aviation Administration on...</td>\n","      <td>80.900002</td>\n","      <td>3428700</td>\n","      <td>8.503224</td>\n","      <td>18.792225</td>\n","      <td>U.S. Federal Aviation Administration Tuesday p...</td>\n","      <td>0.8625</td>\n","      <td>1.0</td>\n","      <td>0.555776</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        Date                                             Header  \\\n","0 2017-03-07  United looking at second-hand aircraft, rules ...   \n","1 2017-04-07     UAL pilots attack U.S. Airways merger prospect   \n","2 2017-04-11  United Airlines faces mounting pressure over h...   \n","3 2017-04-17  United Air removes couple traveling to wedding...   \n","4 2017-04-27  United Airlines reaches settlement with passen...   \n","5 2017-05-02  U.S. lawmakers grill airline executives after ...   \n","6 2017-05-04  United Air to face second congressional grilli...   \n","7 2017-05-30  U.S. proposes fining United $435,000 over 2014...   \n","\n","                                                Text       Open    Volume  \\\n","0   - United Continental Holdings UAKL.N is inter...  72.690002   3764000   \n","1   - United Airlines' pilots union lashed out ag...  69.970001   2471100   \n","2   - United Airlines UAL.N and its chief executi...  70.150002  17696500   \n","3   - An engaged couple were removed from a Unite...  69.510002   4761900   \n","4   - United Airlines UAL.N and the passenger who...  69.769997   5512200   \n","5   - U.S. lawmakers threatened United Airlines U...  70.430000   5434700   \n","6   - United Airlines will be back in the hot sea...  74.559998   2886300   \n","7   - The U.S. Federal Aviation Administration on...  80.900002   3428700   \n","\n","   % Change in Stock Price  % Change in Volume  \\\n","0                      NaN                 NaN   \n","1                -3.741919          -34.349097   \n","2                 0.257255          616.138562   \n","3                -0.912331          -73.091289   \n","4                 0.374040           15.756316   \n","5                 0.945970           -1.405972   \n","6                 5.863976          -46.891273   \n","7                 8.503224           18.792225   \n","\n","                                        Text (clean)  Vader Sentiment Score  \\\n","0  United Continental Holdings UAKL.N interested ...                 0.9485   \n","1  United Airlines pilot union lash effort merge ...                 0.9981   \n","2  United Airlines UAL.N chief executive face mou...                 0.9877   \n","3  engage couple remove United Airlines flight Co...                 0.9501   \n","4  United Airlines UAL.N passenger drag Chicago f...                 0.9136   \n","5  U.S. lawmaker threaten United Airlines UAL.N c...                 0.9460   \n","6  United Airlines hot seat Thursday U.S. Congres...                 0.9921   \n","7  U.S. Federal Aviation Administration Tuesday p...                 0.8625   \n","\n","   sentiment  sentiment_prob  \n","0        1.0        0.693857  \n","1        0.0        0.000993  \n","2        0.0        0.016640  \n","3        0.0        0.100505  \n","4        0.0        0.003089  \n","5        0.0        0.000056  \n","6        0.0        0.038520  \n","7        1.0        0.555776  "]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"id":"9JC_Pen7Ddau"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LBkpL_NhDdau"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ele6w9jUDdau"},"source":[""],"execution_count":null,"outputs":[]}]}