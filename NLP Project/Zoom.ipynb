{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "WyMI88bxSQqX"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import dateutil.parser\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0AD0Rma8SQqX"
   },
   "outputs": [],
   "source": [
    "# dictionary of text dates and links (June 2020 to September 2020)\n",
    "\n",
    "date1 = '2020-06-02' \n",
    "url1 = 'https://www.reuters.com/article/us-zoom-video-commn-results/zoom-doubles-forecast-for-full-year-revenue-on-remote-work-boost-idUSKBN2392XF'\n",
    "\n",
    "date2 = '2020-06-11'\n",
    "url2 = 'https://www.reuters.com/article/zoom-video-commn-privacy-idUSL4N2DO4A4'\n",
    "\n",
    "date3 = '2020-06-11'\n",
    "url3 = 'https://www.reuters.com/article/zoom-video-commn-privacy-idUSL4N2DO4A4'\n",
    "\n",
    "date4 = '2020-06-24'\n",
    "url4 = 'https://www.reuters.com/article/us-zoom-video-commn-moves-jason-lee-idUSKBN23V2PN'\n",
    "\n",
    "\n",
    "date5 = '2020-07-01'\n",
    "url5 = 'https://www.reuters.com/article/us-zoom-video-commn-privacy-idUSKBN2425ZU'\n",
    "\n",
    "date6 = '2020-07-07'\n",
    "url6 = 'https://www.reuters.com/article/us-zoom-video-commn-hardware-idUSKBN2481ZK'\n",
    "\n",
    "date7 = '2020-07-16'\n",
    "url7 = 'https://www.reuters.com/article/us-motor-f1-zoom-idUSKCN24H1FG'\n",
    "\n",
    "date8 = '2020-07-21'\n",
    "url8 = 'https://www.reuters.com/article/us-zoom-video-commn-india-idUSKCN24M0YL'\n",
    "\n",
    "date9 = '2020-07-30'\n",
    "url9 = 'https://www.reuters.com/article/us-usa-china-tiktok-zoom/senators-urge-u-s-justice-department-to-probe-tiktok-zoom-idUSKCN24V36O?'\n",
    "\n",
    "date10 = '2020-08-18'\n",
    "url10 = 'https://www.reuters.com/article/us-zoom-singapore-data-centre-idUSKCN25E188'\n",
    "\n",
    "date11 = '2020-08-24'\n",
    "url11 = 'https://in.reuters.com/article/us-zoom-video-commn-outages/zoom-says-service-restored-after-u-s-users-hit-by-partial-outage-idINKBN25K1NT'\n",
    "\n",
    "date12 = '2020-08-31'\n",
    "url12 = 'https://www.reuters.com/article/zoom-video-commn-results/zoom-beats-quarterly-revenue-estimates-on-remote-work-boost-idINL4N2FX4GW'\n",
    "\n",
    "date13 = '2020-09-01'\n",
    "url13 = 'https://www.reuters.com/article/us-health-coronavirus-finance-breakingvi-idUSKBN25S4RO'\n",
    "\n",
    "date14 = '2020-09-08'\n",
    "url14 = 'https://www.reuters.com/article/us-indonesia-tax-digital/indonesia-adds-twitter-zoom-to-tech-companies-that-must-pay-10-vat-idUSKBN25Z2CU'\n",
    "\n",
    "date15 = '2020-09-15'\n",
    "url15 = 'https://www.reuters.com/article/zoom-video-commn-results-int-idUSKBN25R2QV'\n",
    "\n",
    "\n",
    "\n",
    "url_dict = {date1:url1,\n",
    "            date2:url2,\n",
    "            date3:url3,\n",
    "            date4:url4,\n",
    "            date5:url5,\n",
    "            date6:url6,\n",
    "            date7:url7,\n",
    "            date8:url8,\n",
    "            date9:url9,\n",
    "            date10:url10,\n",
    "            date11:url11,\n",
    "            date12:url12,\n",
    "            date13:url13,\n",
    "            date14:url14,\n",
    "            date15:url15\n",
    "           }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8QdZBTyeSQqX",
    "outputId": "95c0d704-82e0-49f9-9841-b9835655700e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoom nearly doubles revenue forecast on remote-work boost, but costs rising\n",
      "Zoom denies giving user information to Chinese government\n",
      "Zoom taps former Salesforce executive as information security head\n",
      "Zoom says added over 100 features as part of 90-day security plan\n",
      "Zoom rolls out hardware subscription service\n",
      "Formula One, Zoom announce partnership for virtual Paddock Club\n",
      "Zoom to open tech centre in India's Bengaluru\n",
      "Senators urge U.S. Justice Department to probe TikTok, Zoom\n",
      "Zoom opens new data center in Singapore\n",
      "Zoom says service restored after U.S. users hit by partial outage\n",
      "Zoom beats quarterly revenue estimates on remote work boost\n",
      "Breakingviews - Corona Capital: Zooming through Covid\n",
      "Indonesia adds Twitter, Zoom to tech companies that must pay 10% VAT\n",
      "Zoom forecasts sales surge as video conferencing becomes a daily routine\n"
     ]
    }
   ],
   "source": [
    "for key in url_dict:\n",
    "    page = requests.get(url_dict[key]).text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    print(soup.find('h1').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9BEWAuFBSQqY"
   },
   "outputs": [],
   "source": [
    "# extract info from each website and store it in dataframe\n",
    "df_text = pd.DataFrame(columns = ['Date','Header','Text'])\n",
    "header = []\n",
    "text = []\n",
    "date = []\n",
    "for key in url_dict:\n",
    "    page = requests.get(url_dict[key]).text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    date.append(datetime.strptime(key, '%Y-%m-%d').date())\n",
    "    url_header = soup.find('h1').text\n",
    "    \n",
    "    header.append(url_header)\n",
    "    url_text = soup.find('div', class_ = 'ArticleBodyWrapper').text\n",
    "    text.append(url_text)\n",
    "df_text['Date']=date\n",
    "df_text['Header']=header\n",
    "df_text['Text']=text\n",
    "\n",
    "# remove the author and \"min read\" sections\n",
    "df_text_temp = [] \n",
    "for text in df_text['Text']:\n",
    "    loc = text.find('(Reuters)')\n",
    "    df_text_temp.append(text[loc+9:])\n",
    "df_text['Text'] = df_text_temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "98DOlrp4SQqY",
    "outputId": "338a8fa2-96fc-4716-dfcc-f2cb842d8ed7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Header</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-02</td>\n",
       "      <td>Zoom nearly doubles revenue forecast on remote...</td>\n",
       "      <td>- Zoom Video Communications Inc ZM.O nearly d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-11</td>\n",
       "      <td>Zoom denies giving user information to Chinese...</td>\n",
       "      <td>- Zoom Video Communications Inc said on Thurs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-24</td>\n",
       "      <td>Zoom taps former Salesforce executive as infor...</td>\n",
       "      <td>- Zoom Video Communications Inc on Wednesday ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>Zoom says added over 100 features as part of 9...</td>\n",
       "      <td>- Zoom Video Communications Inc said on Wedne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>Zoom rolls out hardware subscription service</td>\n",
       "      <td>- Zoom Video Communications Inc ZM.O said on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                                             Header  \\\n",
       "0 2020-06-02  Zoom nearly doubles revenue forecast on remote...   \n",
       "1 2020-06-11  Zoom denies giving user information to Chinese...   \n",
       "2 2020-06-24  Zoom taps former Salesforce executive as infor...   \n",
       "3 2020-07-01  Zoom says added over 100 features as part of 9...   \n",
       "4 2020-07-07       Zoom rolls out hardware subscription service   \n",
       "\n",
       "                                                Text  \n",
       "0   - Zoom Video Communications Inc ZM.O nearly d...  \n",
       "1   - Zoom Video Communications Inc said on Thurs...  \n",
       "2   - Zoom Video Communications Inc on Wednesday ...  \n",
       "3   - Zoom Video Communications Inc said on Wedne...  \n",
       "4   - Zoom Video Communications Inc ZM.O said on ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text['Date'] = df_text['Date'].apply(lambda x: pd.to_datetime(x))\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VyIwimBvSQqY",
    "outputId": "6e80d795-93fc-4415-a757-83dfe4d4c3c1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-02</td>\n",
       "      <td>74.059998</td>\n",
       "      <td>3138600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>66.720001</td>\n",
       "      <td>2444200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-04</td>\n",
       "      <td>70.500000</td>\n",
       "      <td>2076500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-05</td>\n",
       "      <td>70.029999</td>\n",
       "      <td>3672600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-06</td>\n",
       "      <td>64.260002</td>\n",
       "      <td>11253600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date       Open    Volume\n",
       "0 2019-12-02  74.059998   3138600\n",
       "1 2019-12-03  66.720001   2444200\n",
       "2 2019-12-04  70.500000   2076500\n",
       "3 2019-12-05  70.029999   3672600\n",
       "4 2019-12-06  64.260002  11253600"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import stock data of Zoom\n",
    "df_stock = pd.read_csv('ZM.csv', header=0)\n",
    "\n",
    "df_stock['Date']=df_stock['Date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))\n",
    "\n",
    "\n",
    "df_stock = df_stock.drop(['High','Low','Close','Adj Close'], axis=1)\n",
    "df_stock.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-lfqFFgMSQqZ",
    "outputId": "2870e777-f561-4ba6-b073-95f9f910874b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text['Date'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "oMU9Tcm1SQqZ",
    "outputId": "2d3ba76f-5565-4b58-d857-2c4aba734ba3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stock['Date'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "MKsd-llGSQqZ"
   },
   "outputs": [],
   "source": [
    "# Merge two dataframes\n",
    "df = pd.merge(df_text, df_stock, how='inner', on='Date')\n",
    "df = df.sort_values('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "tqG8kBLISQqZ",
    "outputId": "523dc96c-d9c8-47e0-e3e5-ae41775f4806"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Header</th>\n",
       "      <th>Text</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>% Change in Stock Price</th>\n",
       "      <th>% Change in Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-02</td>\n",
       "      <td>Zoom nearly doubles revenue forecast on remote...</td>\n",
       "      <td>- Zoom Video Communications Inc ZM.O nearly d...</td>\n",
       "      <td>210.250000</td>\n",
       "      <td>36853400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-11</td>\n",
       "      <td>Zoom denies giving user information to Chinese...</td>\n",
       "      <td>- Zoom Video Communications Inc said on Thurs...</td>\n",
       "      <td>219.179993</td>\n",
       "      <td>17615800</td>\n",
       "      <td>4.247321</td>\n",
       "      <td>-52.200340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-24</td>\n",
       "      <td>Zoom taps former Salesforce executive as infor...</td>\n",
       "      <td>- Zoom Video Communications Inc on Wednesday ...</td>\n",
       "      <td>254.500000</td>\n",
       "      <td>9862800</td>\n",
       "      <td>16.114613</td>\n",
       "      <td>-44.011626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>Zoom says added over 100 features as part of 9...</td>\n",
       "      <td>- Zoom Video Communications Inc said on Wedne...</td>\n",
       "      <td>251.350006</td>\n",
       "      <td>6803300</td>\n",
       "      <td>-1.237719</td>\n",
       "      <td>-31.020603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>Zoom rolls out hardware subscription service</td>\n",
       "      <td>- Zoom Video Communications Inc ZM.O said on ...</td>\n",
       "      <td>261.549988</td>\n",
       "      <td>7819700</td>\n",
       "      <td>4.058079</td>\n",
       "      <td>14.939809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                                             Header  \\\n",
       "0 2020-06-02  Zoom nearly doubles revenue forecast on remote...   \n",
       "1 2020-06-11  Zoom denies giving user information to Chinese...   \n",
       "2 2020-06-24  Zoom taps former Salesforce executive as infor...   \n",
       "3 2020-07-01  Zoom says added over 100 features as part of 9...   \n",
       "4 2020-07-07       Zoom rolls out hardware subscription service   \n",
       "\n",
       "                                                Text        Open    Volume  \\\n",
       "0   - Zoom Video Communications Inc ZM.O nearly d...  210.250000  36853400   \n",
       "1   - Zoom Video Communications Inc said on Thurs...  219.179993  17615800   \n",
       "2   - Zoom Video Communications Inc on Wednesday ...  254.500000   9862800   \n",
       "3   - Zoom Video Communications Inc said on Wedne...  251.350006   6803300   \n",
       "4   - Zoom Video Communications Inc ZM.O said on ...  261.549988   7819700   \n",
       "\n",
       "   % Change in Stock Price  % Change in Volume  \n",
       "0                      NaN                 NaN  \n",
       "1                 4.247321          -52.200340  \n",
       "2                16.114613          -44.011626  \n",
       "3                -1.237719          -31.020603  \n",
       "4                 4.058079           14.939809  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show % change in stock price after news article publish\n",
    "pct_stock = df['Open'].pct_change()*100\n",
    "df['% Change in Stock Price'] = pct_stock\n",
    "pct_volume = df['Volume'].pct_change()*100\n",
    "df['% Change in Volume'] = pct_volume\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J07oHTFuSQqZ"
   },
   "source": [
    "\n",
    "# Processing the text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_xGS_KOSQqZ"
   },
   "source": [
    "## import spacy libraries\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "from  spacy.lang.en.stop_words import STOP_WORDS\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "C6ZyQ2WqSQqZ"
   },
   "outputs": [],
   "source": [
    "# import spacy libraries\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "from  spacy.lang.en.stop_words import STOP_WORDS\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "BEImdfNsSQqZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "text_nlp = nlp(df['Text'][1]) \n",
    "# Remove stop words\n",
    "text_nlp_clean = [word for word in text_nlp if word.is_stop == False]\n",
    "# Lemmatize words\n",
    "text_nlp_clean = [word.lemma_ for word in text_nlp_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "LZAg6Uo_SQqZ",
    "outputId": "b22d5f64-31a9-40cd-b78b-7a915c8fbd2c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Header</th>\n",
       "      <th>Text</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>% Change in Stock Price</th>\n",
       "      <th>% Change in Volume</th>\n",
       "      <th>Text (clean)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-02</td>\n",
       "      <td>Zoom nearly doubles revenue forecast on remote...</td>\n",
       "      <td>- Zoom Video Communications Inc ZM.O nearly d...</td>\n",
       "      <td>210.250000</td>\n",
       "      <td>36853400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zoom Video Communications Inc ZM.O nearly doub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-11</td>\n",
       "      <td>Zoom denies giving user information to Chinese...</td>\n",
       "      <td>- Zoom Video Communications Inc said on Thurs...</td>\n",
       "      <td>219.179993</td>\n",
       "      <td>17615800</td>\n",
       "      <td>4.247321</td>\n",
       "      <td>-52.200340</td>\n",
       "      <td>Zoom Video Communications Inc say Thursday pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-24</td>\n",
       "      <td>Zoom taps former Salesforce executive as infor...</td>\n",
       "      <td>- Zoom Video Communications Inc on Wednesday ...</td>\n",
       "      <td>254.500000</td>\n",
       "      <td>9862800</td>\n",
       "      <td>16.114613</td>\n",
       "      <td>-44.011626</td>\n",
       "      <td>Zoom Video Communications Inc Wednesday name S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>Zoom says added over 100 features as part of 9...</td>\n",
       "      <td>- Zoom Video Communications Inc said on Wedne...</td>\n",
       "      <td>251.350006</td>\n",
       "      <td>6803300</td>\n",
       "      <td>-1.237719</td>\n",
       "      <td>-31.020603</td>\n",
       "      <td>Zoom Video Communications Inc say Wednesday ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>Zoom rolls out hardware subscription service</td>\n",
       "      <td>- Zoom Video Communications Inc ZM.O said on ...</td>\n",
       "      <td>261.549988</td>\n",
       "      <td>7819700</td>\n",
       "      <td>4.058079</td>\n",
       "      <td>14.939809</td>\n",
       "      <td>Zoom Video Communications Inc zm.o say Tuesday...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                                             Header  \\\n",
       "0 2020-06-02  Zoom nearly doubles revenue forecast on remote...   \n",
       "1 2020-06-11  Zoom denies giving user information to Chinese...   \n",
       "2 2020-06-24  Zoom taps former Salesforce executive as infor...   \n",
       "3 2020-07-01  Zoom says added over 100 features as part of 9...   \n",
       "4 2020-07-07       Zoom rolls out hardware subscription service   \n",
       "\n",
       "                                                Text        Open    Volume  \\\n",
       "0   - Zoom Video Communications Inc ZM.O nearly d...  210.250000  36853400   \n",
       "1   - Zoom Video Communications Inc said on Thurs...  219.179993  17615800   \n",
       "2   - Zoom Video Communications Inc on Wednesday ...  254.500000   9862800   \n",
       "3   - Zoom Video Communications Inc said on Wedne...  251.350006   6803300   \n",
       "4   - Zoom Video Communications Inc ZM.O said on ...  261.549988   7819700   \n",
       "\n",
       "   % Change in Stock Price  % Change in Volume  \\\n",
       "0                      NaN                 NaN   \n",
       "1                 4.247321          -52.200340   \n",
       "2                16.114613          -44.011626   \n",
       "3                -1.237719          -31.020603   \n",
       "4                 4.058079           14.939809   \n",
       "\n",
       "                                        Text (clean)  \n",
       "0  Zoom Video Communications Inc ZM.O nearly doub...  \n",
       "1  Zoom Video Communications Inc say Thursday pro...  \n",
       "2  Zoom Video Communications Inc Wednesday name S...  \n",
       "3  Zoom Video Communications Inc say Wednesday ad...  \n",
       "4  Zoom Video Communications Inc zm.o say Tuesday...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clean = []\n",
    "for ind, row in df.iterrows():\n",
    "    \n",
    "    # lower casing\n",
    "    text_lower = row['Text'].lower()\n",
    "    \n",
    "    # tokenization\n",
    "    text_nlp = nlp(row['Text']) \n",
    "    \n",
    "    # remove punctuation and empty space\n",
    "    text_nlp_clean = [word for word in text_nlp if not word.is_punct | word.is_space]\n",
    "    \n",
    "    # Remove stop words\n",
    "    text_nlp_clean = [word for word in text_nlp_clean if word.is_stop == False]\n",
    "    \n",
    "    # Lemmatize tokens\n",
    "    text_nlp_clean = [word.lemma_ for word in text_nlp_clean]\n",
    "    \n",
    "    # add preprocessed text to list\n",
    "    text_clean.append(text_nlp_clean)\n",
    "\n",
    "# turn list of strings to string\n",
    "to_string = []\n",
    "for text in text_clean:\n",
    "    to_string.append(' '.join(text))\n",
    "\n",
    "\n",
    "df['Text (clean)'] = to_string\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pd3-9hn1SQqZ"
   },
   "source": [
    "# Using a Pretrained Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "gFOOWs_pSQqZ"
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "uGpOXS8iSQqZ"
   },
   "outputs": [],
   "source": [
    "# a function to return sentiment score\n",
    "def polarity_score(text):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    return sid.polarity_scores(text)['compound']\n",
    "\n",
    "vader_score = []\n",
    "for text in df['Text (clean)']:\n",
    "    score = polarity_score(text)\n",
    "    vader_score.append(score)\n",
    "\n",
    "df['Vader Sentiment Score'] = vader_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "jjdJPjlXSQqZ",
    "outputId": "0c2b02cb-e024-42d2-f69d-762dee29e8d2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Header</th>\n",
       "      <th>Text</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>% Change in Stock Price</th>\n",
       "      <th>% Change in Volume</th>\n",
       "      <th>Text (clean)</th>\n",
       "      <th>Vader Sentiment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-02</td>\n",
       "      <td>Zoom nearly doubles revenue forecast on remote...</td>\n",
       "      <td>- Zoom Video Communications Inc ZM.O nearly d...</td>\n",
       "      <td>210.250000</td>\n",
       "      <td>36853400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zoom Video Communications Inc ZM.O nearly doub...</td>\n",
       "      <td>0.9295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-11</td>\n",
       "      <td>Zoom denies giving user information to Chinese...</td>\n",
       "      <td>- Zoom Video Communications Inc said on Thurs...</td>\n",
       "      <td>219.179993</td>\n",
       "      <td>17615800</td>\n",
       "      <td>4.247321</td>\n",
       "      <td>-52.200340</td>\n",
       "      <td>Zoom Video Communications Inc say Thursday pro...</td>\n",
       "      <td>0.5106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-24</td>\n",
       "      <td>Zoom taps former Salesforce executive as infor...</td>\n",
       "      <td>- Zoom Video Communications Inc on Wednesday ...</td>\n",
       "      <td>254.500000</td>\n",
       "      <td>9862800</td>\n",
       "      <td>16.114613</td>\n",
       "      <td>-44.011626</td>\n",
       "      <td>Zoom Video Communications Inc Wednesday name S...</td>\n",
       "      <td>0.9442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>Zoom says added over 100 features as part of 9...</td>\n",
       "      <td>- Zoom Video Communications Inc said on Wedne...</td>\n",
       "      <td>251.350006</td>\n",
       "      <td>6803300</td>\n",
       "      <td>-1.237719</td>\n",
       "      <td>-31.020603</td>\n",
       "      <td>Zoom Video Communications Inc say Wednesday ad...</td>\n",
       "      <td>0.9628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>Zoom rolls out hardware subscription service</td>\n",
       "      <td>- Zoom Video Communications Inc ZM.O said on ...</td>\n",
       "      <td>261.549988</td>\n",
       "      <td>7819700</td>\n",
       "      <td>4.058079</td>\n",
       "      <td>14.939809</td>\n",
       "      <td>Zoom Video Communications Inc zm.o say Tuesday...</td>\n",
       "      <td>0.9442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                                             Header  \\\n",
       "0 2020-06-02  Zoom nearly doubles revenue forecast on remote...   \n",
       "1 2020-06-11  Zoom denies giving user information to Chinese...   \n",
       "2 2020-06-24  Zoom taps former Salesforce executive as infor...   \n",
       "3 2020-07-01  Zoom says added over 100 features as part of 9...   \n",
       "4 2020-07-07       Zoom rolls out hardware subscription service   \n",
       "\n",
       "                                                Text        Open    Volume  \\\n",
       "0   - Zoom Video Communications Inc ZM.O nearly d...  210.250000  36853400   \n",
       "1   - Zoom Video Communications Inc said on Thurs...  219.179993  17615800   \n",
       "2   - Zoom Video Communications Inc on Wednesday ...  254.500000   9862800   \n",
       "3   - Zoom Video Communications Inc said on Wedne...  251.350006   6803300   \n",
       "4   - Zoom Video Communications Inc ZM.O said on ...  261.549988   7819700   \n",
       "\n",
       "   % Change in Stock Price  % Change in Volume  \\\n",
       "0                      NaN                 NaN   \n",
       "1                 4.247321          -52.200340   \n",
       "2                16.114613          -44.011626   \n",
       "3                -1.237719          -31.020603   \n",
       "4                 4.058079           14.939809   \n",
       "\n",
       "                                        Text (clean)  Vader Sentiment Score  \n",
       "0  Zoom Video Communications Inc ZM.O nearly doub...                 0.9295  \n",
       "1  Zoom Video Communications Inc say Thursday pro...                 0.5106  \n",
       "2  Zoom Video Communications Inc Wednesday name S...                 0.9442  \n",
       "3  Zoom Video Communications Inc say Wednesday ad...                 0.9628  \n",
       "4  Zoom Video Communications Inc zm.o say Tuesday...                 0.9442  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCCCSJYUSQqZ"
   },
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "r1DLbsT1SQqZ"
   },
   "outputs": [],
   "source": [
    "# run this cell to import nltk\n",
    "import nltk\n",
    "from os import getcwd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import twitter_samples \n",
    "from utils import process_tweet, build_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "JdUCmyodSQqZ",
    "outputId": "aad0bb87-821f-4290-b8f1-4cf25b1ca358"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\aashi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aashi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('twitter_samples')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "nAs2hhHySQqZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "# select the set of positive and negative tweets\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "cZGFfVYySQqZ"
   },
   "outputs": [],
   "source": [
    "# split the data into two pieces (80-20), one for training and one for testing (validation set)  \n",
    "test_pos = all_positive_tweets[4000:]\n",
    "train_pos = all_positive_tweets[:4000]\n",
    "test_neg = all_negative_tweets[4000:]\n",
    "train_neg = all_negative_tweets[:4000]\n",
    "\n",
    "train_x = train_pos + train_neg \n",
    "test_x = test_pos + test_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "nZv6mxN1SQqZ"
   },
   "outputs": [],
   "source": [
    "# combine positive and negative labels\n",
    "train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n",
    "test_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "8oiWYMvWSQqZ",
    "outputId": "4d9f4210-8019-4653-9d32-33da87124047"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_y.shape = (8000, 1)\n",
      "test_y.shape = (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape train and test sets\n",
    "print(\"train_y.shape = \" + str(train_y.shape))\n",
    "print(\"test_y.shape = \" + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "LxnndIYPSQqZ",
    "outputId": "646ac697-ce74-4469-ff5a-050f13e54a33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(freqs) = <class 'dict'>\n",
      "len(freqs) = 11340\n"
     ]
    }
   ],
   "source": [
    "# create frequency dictionary\n",
    "freqs = build_freqs(train_x, train_y)\n",
    "\n",
    "# check the output\n",
    "print(\"type(freqs) = \" + str(type(freqs)))\n",
    "print(\"len(freqs) = \" + str(len(freqs.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "-cZaOM1gSQqZ"
   },
   "outputs": [],
   "source": [
    "# UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def extract_features(tweet, freqs):\n",
    "    '''\n",
    "    Input: \n",
    "        tweet: a list of words for one tweet\n",
    "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
    "    Output: \n",
    "        x: a feature vector of dimension (1,3)\n",
    "    '''\n",
    "    # process_tweet tokenizes, stems, and removes stopwords\n",
    "    word_l = process_tweet(tweet)\n",
    "    \n",
    "    # 3 elements in the form of a 1 x 3 vector\n",
    "    x = np.zeros((1, 3)) \n",
    "    \n",
    "    #bias term is set to 1\n",
    "    x[0,0] = 1 \n",
    "    \n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    \n",
    "    # loop through each word in the list of words\n",
    "    for word in word_l:\n",
    "        \n",
    "        # increment the word count for the positive label 1\n",
    "        \n",
    "        x[0,1] += freqs.get((word,1),0)\n",
    "        \n",
    "        # increment the word count for the negative label 0\n",
    "        x[0,2] += freqs.get((word,0),0)\n",
    "        \n",
    "    ### END CODE HERE ###\n",
    "    assert(x.shape == (1, 3))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "A6bTxr6uSQqZ"
   },
   "outputs": [],
   "source": [
    "# collect the features 'x' and stack them into a matrix 'X'\n",
    "X = np.zeros((len(train_x), 3))\n",
    "for i in range(len(train_x)):\n",
    "    X[i, :]= extract_features(train_x[i], freqs)\n",
    "\n",
    "# training labels corresponding to X\n",
    "Y = train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "dRoTKKTBSQqZ",
    "outputId": "15cdb5e0-8aea-45a2-9cea-2127d7cbd672"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnsEVHP5SQqa"
   },
   "source": [
    "### SVM Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "AK4KHYrpSQqa",
    "outputId": "f5a09f16-61ab-49c0-fbc1-715eb6e4e009"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aashi\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Logistic Regression to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "c95ctAe8SQqa"
   },
   "outputs": [],
   "source": [
    "\n",
    "# UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def predict_tweet(tweet, freqs):\n",
    "    '''\n",
    "    Input: \n",
    "        tweet: a string\n",
    "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
    "        theta: (3,1) vector of weights\n",
    "    Output: \n",
    "        y_pred: the probability of a tweet being positive or negative\n",
    "    '''\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    \n",
    "    # extract the features of the tweet and store it into x\n",
    "    x = extract_features(tweet,freqs)\n",
    "    \n",
    "    # make the prediction using x and theta\n",
    "    y_pred = classifier.predict(x)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "R4azdYg0SQqa"
   },
   "outputs": [],
   "source": [
    "# UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def predict_tweet_prob(tweet, freqs):\n",
    "    '''\n",
    "    Input: \n",
    "        tweet: a string\n",
    "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
    "        theta: (3,1) vector of weights\n",
    "    Output: \n",
    "        y_pred: the probability of a tweet being positive or negative\n",
    "    '''\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    \n",
    "    # extract the features of the tweet and store it into x\n",
    "    x = extract_features(tweet,freqs)\n",
    "    \n",
    "    # make the prediction using x and theta\n",
    "    y_pred = classifier.predict_proba(x)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "zXVJRRfXSQqa",
    "outputId": "19b23787-818f-4748-b363-86fae931f665"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "my_tweet = 'The plot was terrible and I was sad until the ending!'\n",
    "predict_tweet(my_tweet, freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16x-YBTt6wG6"
   },
   "source": [
    "#DEEP LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WW8AV0Fi54F6"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import sklearn.metrics\n",
    "import tensorflow as tf\n",
    "from scipy.special import softmax\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "import torch\n",
    "import torchtext\n",
    "import torchtext.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from scipy.special import softmax\n",
    "from torchtext.vocab import Vocab\n",
    "from nltk.corpus import twitter_samples \n",
    "\n",
    "nlp = spacy.load('en')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F5gGAecc54nQ"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NlzygEfN54x-"
   },
   "outputs": [],
   "source": [
    "# %% ----------------------------------- Hyper Parameters --------------------------------------------------------------\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.seq_len = \"get_max_from_data\"\n",
    "        self.embedding_dim = 50\n",
    "        self.n_epochs = 10\n",
    "        self.lr = 1e-2\n",
    "        self.batch_size = 512\n",
    "        self.train = True\n",
    "        self.save_model = True\n",
    "\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6MyB9f9X54WU"
   },
   "outputs": [],
   "source": [
    "# %% ----------------------------------- Helper Functions --------------------------------------------------------------\n",
    "def acc(x, y, return_labels=False):\n",
    "    with torch.no_grad():\n",
    "        logits = torch.empty(len(x), 2)\n",
    "        for batch in range(len(x) // args.batch_size + 1):\n",
    "            inds = slice(batch * args.batch_size, (batch + 1) * args.batch_size)\n",
    "            logits[inds] = model(x[inds])\n",
    "        pred_labels = np.argmax(logits.cpu().numpy(), axis=1)\n",
    "    if return_labels:\n",
    "        return pred_labels\n",
    "    else:\n",
    "        return 100*accuracy_score(y.cpu().numpy(), pred_labels)\n",
    "\n",
    "\n",
    "def extract_vocab_dict_and_msl(sentences_train, sentences_dev):\n",
    "    \"\"\" Tokenizes all the sentences and gets a dictionary of unique tokens and also the maximum sequence length \"\"\"\n",
    "    tokens, ms_len = [], 0\n",
    "    for sentence in list(sentences_train) + list(sentences_dev):\n",
    "        tokens_in_sentence = nltk.word_tokenize(sentence)\n",
    "        if ms_len < len(tokens_in_sentence):\n",
    "            ms_len = len(tokens_in_sentence)\n",
    "        tokens += tokens_in_sentence\n",
    "    token_vocab = {key: i for key, i in zip(set(tokens), range(1, len(set(tokens))+1))}\n",
    "    if len(np.unique(list(token_vocab.values()))) != len(token_vocab):\n",
    "        \"There are some rep words...\"\n",
    "    return token_vocab, ms_len\n",
    "\n",
    "\n",
    "def convert_to_ids(raw_sentences, vocab_dict, pad_to):\n",
    "    \"\"\" Takes an NumPy array of raw text sentences and converts to a sequence of token ids \"\"\"\n",
    "    x = np.empty((len(raw_sentences), pad_to))\n",
    "    for idx, sentence in enumerate(raw_sentences):\n",
    "        word_ids = []\n",
    "        for token in nltk.word_tokenize(sentence):\n",
    "            try:\n",
    "                word_ids.append(vocab_dict[token])\n",
    "            except:\n",
    "                word_ids.append(vocab_dict[token])\n",
    "        if pad_to < len(word_ids):\n",
    "            x[idx] = word_ids[:pad_to]\n",
    "        else:\n",
    "            x[idx] = word_ids + [0] * (pad_to - len(word_ids))\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_glove_embeddings(vocab_dict):\n",
    "    with open(\"glove.6B.50d.txt\", \"r\") as s:\n",
    "        glove = s.read()\n",
    "    embeddings_dict = {}\n",
    "    for line in glove.split(\"\\n\")[:-1]:\n",
    "        text = line.split()\n",
    "        if text[0] in vocab_dict:\n",
    "            embeddings_dict[vocab_dict[text[0]]] = torch.from_numpy(np.array(text[1:], dtype=\"float32\"))\n",
    "    return embeddings_dict\n",
    "\n",
    "\n",
    "def get_glove_table(vocab_dict, glove_dict):\n",
    "    lookup_table = torch.empty((len(vocab_dict)+2, 50))\n",
    "    for token_id in sorted(vocab_dict.values()):\n",
    "        if token_id in glove_dict:\n",
    "            lookup_table[token_id] = glove_dict[token_id]\n",
    "        else:\n",
    "            lookup_table[token_id] = torch.zeros((1, 50))  # For unknown tokens\n",
    "    lookup_table[0] = torch.zeros((1, 50))\n",
    "    return lookup_table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3hF8Psy16tY9"
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"original_data/train.tsv\", sep=\"\\t\")\n",
    "x_train_raw, y_train = data_train[\"sentence\"].values, torch.LongTensor(data_train[\"label\"].values).to(device)\n",
    "data_dev = pd.read_csv(\"original_data/dev.tsv\", sep=\"\\t\")\n",
    "x_dev_raw, y_dev = data_dev[\"sentence\"].values, torch.LongTensor(data_dev[\"label\"].values).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3jKrMWVE6s-9"
   },
   "outputs": [],
   "source": [
    "# %% -------------------------------------- Data Prep ------------------------------------------------------------------\n",
    "try:\n",
    "    with open(\"example_prep_data/vocab_dict.json\", \"r\") as s:\n",
    "        token_ids = json.load(s)\n",
    "    msl = np.load(\"example_prep_data/max_sequence_length.npy\").item()\n",
    "except:\n",
    "    print(\"Tokenizing all the examples to get a vocab dict and the maximum sequence length...\")\n",
    "    token_ids, msl = extract_vocab_dict_and_msl(x_train_raw, x_dev_raw)\n",
    "    os.mkdir(\"example_prep_data\")\n",
    "    with open(\"example_prep_data/vocab_dict.json\", \"w\") as s:\n",
    "        json.dump(token_ids, s)\n",
    "    np.save(\"example_prep_data/max_sequence_length.npy\", np.array([msl]))\n",
    "if args.seq_len == \"get_max_from_data\":\n",
    "    args.seq_len = msl\n",
    "\n",
    "glove_embeddings = get_glove_embeddings(token_ids)\n",
    "\n",
    "try:\n",
    "    x_train = np.load(\"example_prep_data/prep_train_len{}.npy\".format(args.seq_len))\n",
    "    x_dev = np.load(\"example_prep_data/prep_dev_len{}.npy\".format(args.seq_len))\n",
    "except:\n",
    "    print(\"Converting all the sentences to sequences of token ids...\")\n",
    "    x_train = convert_to_ids(x_train_raw, token_ids, args.seq_len)\n",
    "    np.save(\"example_prep_data/prep_train_len{}.npy\".format(args.seq_len), x_train)\n",
    "    x_dev = convert_to_ids(x_dev_raw, token_ids, args.seq_len)\n",
    "    np.save(\"example_prep_data/prep_dev_len{}.npy\".format(args.seq_len), x_dev)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H8I67K-d6s0i"
   },
   "outputs": [],
   "source": [
    "x_train, x_dev = torch.LongTensor(x_train).to(device), torch.LongTensor(x_dev).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jCys2Yib6_ND"
   },
   "outputs": [],
   "source": [
    "# %% -------------------------------------- CNN Class ------------------------------------------------------------------\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size + 2, args.embedding_dim)\n",
    "\n",
    "        self.conv1 = nn.Conv1d(args.embedding_dim, args.embedding_dim, 9)\n",
    "        self.convnorm1 = nn.BatchNorm1d(args.embedding_dim)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(args.embedding_dim, args.embedding_dim, 9)\n",
    "        self.convnorm2 = nn.BatchNorm1d(args.embedding_dim)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(args.embedding_dim, args.embedding_dim, 7)\n",
    "        self.linear = nn.Linear(args.embedding_dim, 2)\n",
    "        self.act = torch.relu\n",
    "\n",
    "    def forward(self, x):\n",
    "        # nn.Conv1d operates on the columns, each embedding dimension is considered as one channel\n",
    "        x = self.embedding(x).permute(0, 2, 1)\n",
    "        x = self.pool1(self.convnorm1(self.act(self.conv1(x))))\n",
    "        x = self.pool2(self.convnorm2(self.act(self.conv2(x))))\n",
    "        return self.linear(self.act(self.conv3(x)).reshape(-1, args.embedding_dim))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5rPDonKu6_eF"
   },
   "outputs": [],
   "source": [
    "# %% -------------------------------------- Training Prep ----------------------------------------------------------\n",
    "model = CNN(len(token_ids)).to(device)\n",
    "look_up_table = get_glove_table(token_ids, glove_embeddings)\n",
    "model.embedding.weight.data.copy_(look_up_table)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uo_Y8XZM6-9q"
   },
   "outputs": [],
   "source": [
    "# %% -------------------------------------- Training Loop ----------------------------------------------------------\n",
    "labels_ditrib = torch.unique(y_dev, return_counts=True)\n",
    "print(\"The no information rate is {:.2f}\".format(100*labels_ditrib[1].max().item()/len(y_dev)))\n",
    "if args.train:\n",
    "    acc_dev_best = 0\n",
    "    print(\"Starting training loop...\")\n",
    "    for epoch in range(args.n_epochs):\n",
    "\n",
    "        loss_train, train_steps = 0, 0\n",
    "        model.train()\n",
    "        total = len(x_train) // args.batch_size + 1  # Initiates a progress bar that will be updated for each batch\n",
    "        with tqdm(total=total, desc=\"Epoch {}\".format(epoch)) as pbar:  # \"Epoch\" will be updated for each epoch\n",
    "            for batch in range(len(x_train)//args.batch_size + 1):\n",
    "                inds = slice(batch*args.batch_size, (batch+1)*args.batch_size)\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(x_train[inds])\n",
    "                loss = criterion(logits, y_train[inds])\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss_train += loss.item()\n",
    "                train_steps += 1\n",
    "                pbar.update(1)  # Updates the progress and the training loss\n",
    "                pbar.set_postfix_str(\"Training Loss: {:.5f}\".format(loss_train / train_steps))\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_dev_pred = model(x_dev)\n",
    "            loss = criterion(y_dev_pred, y_dev)\n",
    "            loss_test = loss.item()\n",
    "\n",
    "        acc_dev = acc(x_dev, y_dev)\n",
    "        print(\"Epoch {} | Train Loss {:.5f}, Train Acc {:.2f} - Test Loss {:.5f}, Test Acc {:.2f}\".format(\n",
    "            epoch, loss_train/train_steps, acc(x_train, y_train), loss_test, acc_dev))\n",
    "\n",
    "        if acc_dev > acc_dev_best and args.save_model:\n",
    "            torch.save(model.state_dict(), \"cnn_sentiment.pt\")\n",
    "            print(\"The model has been saved!\")\n",
    "            acc_dev_best = acc_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FDSz9agy7nl1"
   },
   "source": [
    "# Test of Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zhc9VEVT9OpC"
   },
   "outputs": [],
   "source": [
    "x = None\n",
    "for i in range(10):\n",
    "    test = convert_to_ids([x_train_raw[i]], token_ids, args.seq_len)\n",
    "    test = torch.LongTensor(test).to(device)\n",
    "    pred = model(test).cpu().detach().numpy()[0]\n",
    "    x = softmax(pred)\n",
    "    print(softmax(pred),y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qL3t7fdC9Rg2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agoddrKE7U6y"
   },
   "outputs": [],
   "source": [
    "x = None\n",
    "deep_learning_sentiment_prob = []\n",
    "\n",
    "for i in df.iloc[:,2]:\n",
    "    test = convert_to_ids([i], token_ids, args.seq_len)\n",
    "    test = torch.LongTensor(test).to(device)\n",
    "    pred = model(test).cpu().detach().numpy()[0]\n",
    "    x = softmax(pred)\n",
    "    sentiment_prob.append(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ceKT6AHr7Ubk"
   },
   "outputs": [],
   "source": [
    "df['deep_learning_sentiment_prob'] = sentiment_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5Qr2b_W9gNj"
   },
   "source": [
    "#END OF DEEP LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxKSAa0JSQqa"
   },
   "source": [
    "# Testing the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "emRuurQVSQqa"
   },
   "outputs": [],
   "source": [
    "sentiment = []\n",
    "sentiment_prob = []\n",
    "for i in df.iloc[:,2]:\n",
    "    sentiment.append(predict_tweet(i, freqs)[0])\n",
    "    sentiment_prob.append(predict_tweet_prob(i, freqs)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Xi3ZxKOhSQqa",
    "outputId": "8137f13e-3aad-44a6-c20f-47f8e336f052"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "zu2uBb1KSQqa",
    "outputId": "cc82b5ad-d859-471d-b1a8-ffbacd44849b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.34843847625364516,\n",
       " 0.6755430085014102,\n",
       " 0.7609195145575649,\n",
       " 0.9228283272817779,\n",
       " 0.6050521409884354,\n",
       " 0.24438262108230238,\n",
       " 0.19620956838873493,\n",
       " 0.3992342993835243,\n",
       " 0.41324759211955014,\n",
       " 0.09907528846684727,\n",
       " 0.7638819753506009,\n",
       " 0.0034492514897051713,\n",
       " 0.8662636828470726,\n",
       " 0.45439296762724446]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "7roC_ubHSQqa",
    "outputId": "a6cfb2ad-1208-43c1-c1c6-32a05ccf60e8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Header</th>\n",
       "      <th>Text</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>% Change in Stock Price</th>\n",
       "      <th>% Change in Volume</th>\n",
       "      <th>Text (clean)</th>\n",
       "      <th>Vader Sentiment Score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_prob</th>\n",
       "      <th>Days Elapsed</th>\n",
       "      <th>Average % Change in Stock Price</th>\n",
       "      <th>Average % Change in Volume</th>\n",
       "      <th>Logistic Regresion Sentiment</th>\n",
       "      <th>Logistic Regresion Score</th>\n",
       "      <th>Logistic Regression Sentiment</th>\n",
       "      <th>Logistic Regression Sentiment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-02</td>\n",
       "      <td>Zoom nearly doubles revenue forecast on remote...</td>\n",
       "      <td>- Zoom Video Communications Inc ZM.O nearly d...</td>\n",
       "      <td>210.250000</td>\n",
       "      <td>36853400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zoom Video Communications Inc ZM.O nearly doub...</td>\n",
       "      <td>0.9295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.348438</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.348438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.348438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-11</td>\n",
       "      <td>Zoom denies giving user information to Chinese...</td>\n",
       "      <td>- Zoom Video Communications Inc said on Thurs...</td>\n",
       "      <td>219.179993</td>\n",
       "      <td>17615800</td>\n",
       "      <td>4.247321</td>\n",
       "      <td>-52.20034</td>\n",
       "      <td>Zoom Video Communications Inc say Thursday pro...</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.675543</td>\n",
       "      <td>9</td>\n",
       "      <td>0.471925</td>\n",
       "      <td>-5.800038</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.675543</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.675543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                                             Header  \\\n",
       "0 2020-06-02  Zoom nearly doubles revenue forecast on remote...   \n",
       "1 2020-06-11  Zoom denies giving user information to Chinese...   \n",
       "\n",
       "                                                Text        Open    Volume  \\\n",
       "0   - Zoom Video Communications Inc ZM.O nearly d...  210.250000  36853400   \n",
       "1   - Zoom Video Communications Inc said on Thurs...  219.179993  17615800   \n",
       "\n",
       "   % Change in Stock Price  % Change in Volume  \\\n",
       "0                      NaN                 NaN   \n",
       "1                 4.247321           -52.20034   \n",
       "\n",
       "                                        Text (clean)  Vader Sentiment Score  \\\n",
       "0  Zoom Video Communications Inc ZM.O nearly doub...                 0.9295   \n",
       "1  Zoom Video Communications Inc say Thursday pro...                 0.5106   \n",
       "\n",
       "   sentiment  sentiment_prob  Days Elapsed  Average % Change in Stock Price  \\\n",
       "0        0.0        0.348438             0                              NaN   \n",
       "1        1.0        0.675543             9                         0.471925   \n",
       "\n",
       "   Average % Change in Volume  Logistic Regresion Sentiment  \\\n",
       "0                         NaN                           0.0   \n",
       "1                   -5.800038                           1.0   \n",
       "\n",
       "   Logistic Regresion Score  Logistic Regression Sentiment  \\\n",
       "0                  0.348438                            0.0   \n",
       "1                  0.675543                            1.0   \n",
       "\n",
       "   Logistic Regression Sentiment Score  \n",
       "0                             0.348438  \n",
       "1                             0.675543  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting % stock price change to % stock price change per day\n",
    "days = [0]\n",
    "for i in range(len(df['Date'])):\n",
    "    if i != 0:\n",
    "        date_diff = df['Date'][i]-df['Date'][i-1]\n",
    "        day = date_diff.days\n",
    "        days.append(day)\n",
    "df['Days Elapsed'] = days\n",
    "df['Average % Change in Stock Price'] = df['% Change in Stock Price']/df['Days Elapsed']\n",
    "df['Average % Change in Volume'] = df['% Change in Volume']/df['Days Elapsed']\n",
    "\n",
    "df['Logistic Regression Sentiment'] = sentiment\n",
    "df['Logistic Regression Sentiment Score'] = sentiment_prob\n",
    "\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df[''.quantile(0.25)\n",
    "Q3 = boston_df_o1.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "Yo793wEeSQqa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Average % Change in Stock Price', ylabel='Vader Sentiment Score'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df_scatter = df[['Average % Change in Stock Price','Average % Change in Volume','Vader Sentiment Score','Logistic Regression Sentiment Score']]\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.scatterplot(x =df_scatter['Average % Change in Stock Price'], y = df_scatter['Vader Sentiment Score'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hpOOqZcmSQqa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Zoom.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
