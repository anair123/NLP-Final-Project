{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import dateutil.parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of text dates and links\n",
    "\n",
    "# August 2, 2015\n",
    "url1 = 'https://www.reuters.com/article/us-toyota-sales-idUSKCN0Q805F20150803'\n",
    "\n",
    "# August 18, 2015\n",
    "url2 = 'https://uk.reuters.com/article/uk-china-blast-toyota/global-automakers-divert-shipments-from-chinas-tianjin-port-after-blasts-idUKKCN0QO07W20150819'\n",
    "\n",
    "# September 3, 2015\n",
    "url3 = 'https://www.reuters.com/article/us-volkswagen-chairman-poetsch/vws-finance-chief-set-to-become-new-chairman-idUSKCN0R31B620150903'\n",
    "\n",
    "# September 4, 2-15\n",
    "url4 = 'https://www.reuters.com/article/us-toyota-research-robotics-idUSKCN0R41X220150904'\n",
    "\n",
    "# September 18, 2015\n",
    "url5 = 'https://www.reuters.com/article/us-usa-volkswagen-idUSKCN0RI1VK20150918'\n",
    "\n",
    "# September 21, 2015\n",
    "url6 = 'https://www.reuters.com/article/us-usa-volkswagen-emission-idUSKCN0RL2EI20150922'\n",
    "\n",
    "# September 24, 2015\n",
    "url7 = 'https://www.reuters.com/article/usa-volkswagen-deception-idUSL1N11U1OB20150924'\n",
    "\n",
    "# September 29, 2015\n",
    "url8 = 'https://www.reuters.com/article/volkswagen-emissions-technology-idUSL1N11Z1XQ20150929'\n",
    "\n",
    "\n",
    "# October 8, 2015\n",
    "url9 = 'https://www.reuters.com/article/us-volkswagen-emissions-consumers-insigh-idUSKCN0S20CK20151008'\n",
    "\n",
    "# October 13, 2015\n",
    "url10 = 'https://in.reuters.com/article/us-volkswagen-emissions-investment/vw-looks-to-cutbacks-and-electric-cars-to-overcome-scandal-idUKKCN0S710020151013'\n",
    "\n",
    "# October 21, 2015\n",
    "url11 = 'https://ca.reuters.com/article/businessNews/idCAKCN0SF1FU20151021'\n",
    "\n",
    "# October 22, 2015\n",
    "url12 = 'https://www.reuters.com/article/us-volkswagen-emissions-brazil-idUSKCN0SG1N720151022'\n",
    "\n",
    "\n",
    "# October 28, 2015\n",
    "url13 = 'https://www.reuters.com/article/us-volkswagen-emissions-dealers-idUSKCN0SM2SG20151028'\n",
    "\n",
    "# November 4, 2015\n",
    "url14 = 'https://www.reuters.com/article/us-volkswagen-emissions-idUSKCN0ST1VY20151104'\n",
    "\n",
    "# November 8, 2015\n",
    "url15 = 'https://www.reuters.com/article/volkswagen-emissions/vw-engineers-have-admitted-manipulating-co2-emissions-data-paper-idUKL8N1320KD20151108'\n",
    "\n",
    "url_dict = {'08/02/2015':url1,\n",
    "            '08/18/2015':url2,\n",
    "            '09/03/2015':url3,\n",
    "            '09/04/2015':url4,\n",
    "            '09/18/2015':url5,\n",
    "           '09/21/2015':url6,\n",
    "           '09/24/2015':url7,\n",
    "            '09/29/2015':url8,\n",
    "            '10/08/2015':url9,\n",
    "            '10/13/2015':url10,\n",
    "            '10/21/2015':url11,\n",
    "           '10/22/2015':url12,\n",
    "           '10/28/2015':url13,\n",
    "            '11/04/2015':url14,\n",
    "           '11/08/2015':url15,\n",
    "           }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract info from each website and store it in dataframe\n",
    "df_text = pd.DataFrame(columns = ['Date','Header','Text'])\n",
    "header = []\n",
    "text = []\n",
    "date = []\n",
    "for key in url_dict:\n",
    "    page = requests.get(url_dict[key]).text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    date.append(datetime.strptime(key, '%m/%d/%Y').date())\n",
    "    url_header = soup.find('h1').text\n",
    "    header.append(url_header)\n",
    "    url_text = soup.find('div', class_ = 'ArticleBodyWrapper').text\n",
    "    text.append(url_text)\n",
    "df_text['Date']=date\n",
    "df_text['Header']=header\n",
    "df_text['Text']=text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Header</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-08-02</td>\n",
       "      <td>Volkswagen overtakes Toyota as world's biggest...</td>\n",
       "      <td>By Andreas Cremer, Minami Funakoshi3 Min Read(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-08-18</td>\n",
       "      <td>Global automakers divert shipments from China'...</td>\n",
       "      <td>By Norihiko Shirouzu, Jake Spring3 Min ReadBEI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-09-03</td>\n",
       "      <td>VW's finance chief set to become new chairman</td>\n",
       "      <td>By Andreas Cremer4 Min ReadBERLIN (Reuters) - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-09-04</td>\n",
       "      <td>Toyota partners with Stanford, MIT on self-dri...</td>\n",
       "      <td>By Paul Lienert2 Min ReadA woman looks inside ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-09-18</td>\n",
       "      <td>Volkswagen could face $18 billion penalties fr...</td>\n",
       "      <td>By Timothy Gardner, Bernie Woodall3 Min ReadWA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                             Header  \\\n",
       "0  2015-08-02  Volkswagen overtakes Toyota as world's biggest...   \n",
       "1  2015-08-18  Global automakers divert shipments from China'...   \n",
       "2  2015-09-03      VW's finance chief set to become new chairman   \n",
       "3  2015-09-04  Toyota partners with Stanford, MIT on self-dri...   \n",
       "4  2015-09-18  Volkswagen could face $18 billion penalties fr...   \n",
       "\n",
       "                                                Text  \n",
       "0  By Andreas Cremer, Minami Funakoshi3 Min Read(...  \n",
       "1  By Norihiko Shirouzu, Jake Spring3 Min ReadBEI...  \n",
       "2  By Andreas Cremer4 Min ReadBERLIN (Reuters) - ...  \n",
       "3  By Paul Lienert2 Min ReadA woman looks inside ...  \n",
       "4  By Timothy Gardner, Bernie Woodall3 Min ReadWA...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-11-20</td>\n",
       "      <td>511.0</td>\n",
       "      <td>192.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-11-19</td>\n",
       "      <td>1338.0</td>\n",
       "      <td>189.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-18</td>\n",
       "      <td>4359.0</td>\n",
       "      <td>189.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-17</td>\n",
       "      <td>1456.0</td>\n",
       "      <td>193.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>190.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Volume    Open\n",
       "0  2020-11-20    511.0  192.99\n",
       "1  2020-11-19   1338.0  189.50\n",
       "2  2020-11-18   4359.0  189.80\n",
       "3  2020-11-17   1456.0  193.60\n",
       "4  2020-11-16   1224.0  190.25"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import stock data of netflix\n",
    "df_stock = pd.read_csv('Volkswagen.csv', header=0)\n",
    "df_stock['Date']=df_stock['Date'].apply(lambda x: datetime.strptime(x, '%m/%d/%Y').date())\n",
    "\n",
    "df_stock = df_stock[df_stock[' Volume'] != ' N/A']\n",
    "\n",
    "# Remove $ sign and change to int variable\n",
    "df_stock[' Open'] = df_stock[' Open'].apply(lambda x : x[1:])\n",
    "df_stock[' High'] = df_stock[' High'].apply(lambda x : x[1:])\n",
    "df_stock[' Low'] = df_stock[' Low'].apply(lambda x : x[1:])\n",
    "df_stock[' Close/Last'] = df_stock[' Close/Last'].apply(lambda x : x[1:])\n",
    "\n",
    "# Remove $ sign and change to int variable\n",
    "df_stock[' Open'] = df_stock[' Open'].astype(float)\n",
    "df_stock[' High'] = df_stock[' High'].astype(float)\n",
    "df_stock[' Volume'] = df_stock[' Volume'].astype(float)\n",
    "df_stock[' Low'] = df_stock[' Low'].astype(float)\n",
    "df_stock[' Close/Last'] = df_stock[' Close/Last'].astype(float)\n",
    "\n",
    "columns_remove = [' High', ' Low', ' Close/Last']\n",
    "df_stock = df_stock.drop(columns_remove, axis=1)\n",
    "\n",
    "\n",
    "df_stock.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge two dataframes\n",
    "df = pd.merge(df_text, df_stock, how='inner', on='Date')\n",
    "df = df.sort_values('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Header</th>\n",
       "      <th>Text</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>% Change in Stock Price</th>\n",
       "      <th>% Change in Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-08-18</td>\n",
       "      <td>Global automakers divert shipments from China'...</td>\n",
       "      <td>By Norihiko Shirouzu, Jake Spring3 Min ReadBEI...</td>\n",
       "      <td>351.0</td>\n",
       "      <td>191.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-09-03</td>\n",
       "      <td>VW's finance chief set to become new chairman</td>\n",
       "      <td>By Andreas Cremer4 Min ReadBERLIN (Reuters) - ...</td>\n",
       "      <td>295.0</td>\n",
       "      <td>180.10</td>\n",
       "      <td>-5.953003</td>\n",
       "      <td>-15.954416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-09-04</td>\n",
       "      <td>Toyota partners with Stanford, MIT on self-dri...</td>\n",
       "      <td>By Paul Lienert2 Min ReadA woman looks inside ...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>177.20</td>\n",
       "      <td>-1.610217</td>\n",
       "      <td>-82.711864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-09-18</td>\n",
       "      <td>Volkswagen could face $18 billion penalties fr...</td>\n",
       "      <td>By Timothy Gardner, Bernie Woodall3 Min ReadWA...</td>\n",
       "      <td>209.0</td>\n",
       "      <td>185.60</td>\n",
       "      <td>4.740406</td>\n",
       "      <td>309.803922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-09-21</td>\n",
       "      <td>Volkswagen's 'clean diesel' strategy unraveled...</td>\n",
       "      <td>By Paul Lienert, Timothy Gardner4 Min ReadDETR...</td>\n",
       "      <td>20900.0</td>\n",
       "      <td>149.88</td>\n",
       "      <td>-19.245690</td>\n",
       "      <td>9900.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                             Header  \\\n",
       "0  2015-08-18  Global automakers divert shipments from China'...   \n",
       "1  2015-09-03      VW's finance chief set to become new chairman   \n",
       "2  2015-09-04  Toyota partners with Stanford, MIT on self-dri...   \n",
       "3  2015-09-18  Volkswagen could face $18 billion penalties fr...   \n",
       "4  2015-09-21  Volkswagen's 'clean diesel' strategy unraveled...   \n",
       "\n",
       "                                                Text   Volume    Open  \\\n",
       "0  By Norihiko Shirouzu, Jake Spring3 Min ReadBEI...    351.0  191.50   \n",
       "1  By Andreas Cremer4 Min ReadBERLIN (Reuters) - ...    295.0  180.10   \n",
       "2  By Paul Lienert2 Min ReadA woman looks inside ...     51.0  177.20   \n",
       "3  By Timothy Gardner, Bernie Woodall3 Min ReadWA...    209.0  185.60   \n",
       "4  By Paul Lienert, Timothy Gardner4 Min ReadDETR...  20900.0  149.88   \n",
       "\n",
       "   % Change in Stock Price  % Change in Volume  \n",
       "0                      NaN                 NaN  \n",
       "1                -5.953003          -15.954416  \n",
       "2                -1.610217          -82.711864  \n",
       "3                 4.740406          309.803922  \n",
       "4               -19.245690         9900.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show % change in stock price after news article publish\n",
    "pct_stock = df[' Open'].pct_change()*100\n",
    "df['% Change in Stock Price'] = pct_stock\n",
    "pct_volume = df[' Volume'].pct_change()*100\n",
    "df['% Change in Volume'] = pct_volume\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import spacy libraries\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "from  spacy.lang.en.stop_words import STOP_WORDS\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy libraries\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "from  spacy.lang.en.stop_words import STOP_WORDS\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_nlp = nlp(df['Text'][1]) \n",
    "# Remove stop words\n",
    "text_nlp_clean = [word for word in text_nlp if word.is_stop == False]\n",
    "# Lemmatize words\n",
    "text_nlp_clean = [word.lemma_ for word in text_nlp_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clean = []\n",
    "for ind, row in df.iterrows():\n",
    "    \n",
    "    # lower casing\n",
    "    text_lower = row['Text'].lower()\n",
    "    \n",
    "    # tokenization\n",
    "    text_nlp = nlp(row['Text']) \n",
    "    \n",
    "    # remove punctuation and empty space\n",
    "    text_nlp_clean = [word for word in text_nlp if not word.is_punct | word.is_space]\n",
    "    \n",
    "    # Remove stop words\n",
    "    text_nlp_clean = [word for word in text_nlp_clean if word.is_stop == False]\n",
    "    \n",
    "    # Lemmatize tokens\n",
    "    text_nlp_clean = [word.lemma_ for word in text_nlp_clean]\n",
    "    \n",
    "    # add preprocessed text to list\n",
    "    text_clean.append(text_nlp_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Pretrained Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to return sentiment score\n",
    "def polarity_score(text):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    return sid.polarity_scores(text)['compound']\n",
    "\n",
    "vader_score = []\n",
    "for text in df['Text']:\n",
    "    score = polarity_score(text)\n",
    "    vader_score.append(score)\n",
    "\n",
    "df['Vader Sentiment Score'] = vader_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Header</th>\n",
       "      <th>Text</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>% Change in Stock Price</th>\n",
       "      <th>% Change in Volume</th>\n",
       "      <th>Vader Sentiment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-08-18</td>\n",
       "      <td>Global automakers divert shipments from China'...</td>\n",
       "      <td>By Norihiko Shirouzu, Jake Spring3 Min ReadBEI...</td>\n",
       "      <td>351.0</td>\n",
       "      <td>191.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.9686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-09-03</td>\n",
       "      <td>VW's finance chief set to become new chairman</td>\n",
       "      <td>By Andreas Cremer4 Min ReadBERLIN (Reuters) - ...</td>\n",
       "      <td>295.0</td>\n",
       "      <td>180.10</td>\n",
       "      <td>-5.953003</td>\n",
       "      <td>-15.954416</td>\n",
       "      <td>0.9909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-09-04</td>\n",
       "      <td>Toyota partners with Stanford, MIT on self-dri...</td>\n",
       "      <td>By Paul Lienert2 Min ReadA woman looks inside ...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>177.20</td>\n",
       "      <td>-1.610217</td>\n",
       "      <td>-82.711864</td>\n",
       "      <td>0.9273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-09-18</td>\n",
       "      <td>Volkswagen could face $18 billion penalties fr...</td>\n",
       "      <td>By Timothy Gardner, Bernie Woodall3 Min ReadWA...</td>\n",
       "      <td>209.0</td>\n",
       "      <td>185.60</td>\n",
       "      <td>4.740406</td>\n",
       "      <td>309.803922</td>\n",
       "      <td>0.9231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-09-21</td>\n",
       "      <td>Volkswagen's 'clean diesel' strategy unraveled...</td>\n",
       "      <td>By Paul Lienert, Timothy Gardner4 Min ReadDETR...</td>\n",
       "      <td>20900.0</td>\n",
       "      <td>149.88</td>\n",
       "      <td>-19.245690</td>\n",
       "      <td>9900.000000</td>\n",
       "      <td>-0.5574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                             Header  \\\n",
       "0  2015-08-18  Global automakers divert shipments from China'...   \n",
       "1  2015-09-03      VW's finance chief set to become new chairman   \n",
       "2  2015-09-04  Toyota partners with Stanford, MIT on self-dri...   \n",
       "3  2015-09-18  Volkswagen could face $18 billion penalties fr...   \n",
       "4  2015-09-21  Volkswagen's 'clean diesel' strategy unraveled...   \n",
       "\n",
       "                                                Text   Volume    Open  \\\n",
       "0  By Norihiko Shirouzu, Jake Spring3 Min ReadBEI...    351.0  191.50   \n",
       "1  By Andreas Cremer4 Min ReadBERLIN (Reuters) - ...    295.0  180.10   \n",
       "2  By Paul Lienert2 Min ReadA woman looks inside ...     51.0  177.20   \n",
       "3  By Timothy Gardner, Bernie Woodall3 Min ReadWA...    209.0  185.60   \n",
       "4  By Paul Lienert, Timothy Gardner4 Min ReadDETR...  20900.0  149.88   \n",
       "\n",
       "   % Change in Stock Price  % Change in Volume  Vader Sentiment Score  \n",
       "0                      NaN                 NaN                -0.9686  \n",
       "1                -5.953003          -15.954416                 0.9909  \n",
       "2                -1.610217          -82.711864                 0.9273  \n",
       "3                 4.740406          309.803922                 0.9231  \n",
       "4               -19.245690         9900.000000                -0.5574  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to import nltk\n",
    "import nltk\n",
    "from os import getcwd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import twitter_samples \n",
    "from utils import process_tweet, build_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\aashi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aashi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('twitter_samples')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# select the set of positive and negative tweets\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into two pieces (80-20), one for training and one for testing (validation set)  \n",
    "test_pos = all_positive_tweets[4000:]\n",
    "train_pos = all_positive_tweets[:4000]\n",
    "test_neg = all_negative_tweets[4000:]\n",
    "train_neg = all_negative_tweets[:4000]\n",
    "\n",
    "train_x = train_pos + train_neg \n",
    "test_x = test_pos + test_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine positive and negative labels\n",
    "train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n",
    "test_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_y.shape = (8000, 1)\n",
      "test_y.shape = (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape train and test sets\n",
    "print(\"train_y.shape = \" + str(train_y.shape))\n",
    "print(\"test_y.shape = \" + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(freqs) = <class 'dict'>\n",
      "len(freqs) = 11340\n"
     ]
    }
   ],
   "source": [
    "# create frequency dictionary\n",
    "freqs = build_freqs(train_x, train_y)\n",
    "\n",
    "# check the output\n",
    "print(\"type(freqs) = \" + str(type(freqs)))\n",
    "print(\"len(freqs) = \" + str(len(freqs.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def extract_features(tweet, freqs):\n",
    "    '''\n",
    "    Input: \n",
    "        tweet: a list of words for one tweet\n",
    "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
    "    Output: \n",
    "        x: a feature vector of dimension (1,3)\n",
    "    '''\n",
    "    # process_tweet tokenizes, stems, and removes stopwords\n",
    "    word_l = process_tweet(tweet)\n",
    "    \n",
    "    # 3 elements in the form of a 1 x 3 vector\n",
    "    x = np.zeros((1, 3)) \n",
    "    \n",
    "    #bias term is set to 1\n",
    "    x[0,0] = 1 \n",
    "    \n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    \n",
    "    # loop through each word in the list of words\n",
    "    for word in word_l:\n",
    "        \n",
    "        # increment the word count for the positive label 1\n",
    "        \n",
    "        x[0,1] += freqs.get((word,1),0)\n",
    "        \n",
    "        # increment the word count for the negative label 0\n",
    "        x[0,2] += freqs.get((word,0),0)\n",
    "        \n",
    "    ### END CODE HERE ###\n",
    "    assert(x.shape == (1, 3))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect the features 'x' and stack them into a matrix 'X'\n",
    "X = np.zeros((len(train_x), 3))\n",
    "for i in range(len(train_x)):\n",
    "    X[i, :]= extract_features(train_x[i], freqs)\n",
    "\n",
    "# training labels corresponding to X\n",
    "Y = train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.0001, 0.001, 0.01, 0.1, 1]}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gs = GridSearchCV(estimator=svm.SVC(),\n",
    "                 param_grid=param_grid,\n",
    "                 cv=5)\n",
    "gs.fit(X,Y.ravel())\n",
    "\n",
    "# Update best_score_param_estimator_gs\n",
    "classifier = gs.best_estimator_\n",
    "\n",
    "print(classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def predict_tweet(tweet, freqs):\n",
    "    '''\n",
    "    Input: \n",
    "        tweet: a string\n",
    "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
    "        theta: (3,1) vector of weights\n",
    "    Output: \n",
    "        y_pred: the probability of a tweet being positive or negative\n",
    "    '''\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    \n",
    "    # extract the features of the tweet and store it into x\n",
    "    x = extract_features(tweet,freqs)\n",
    "    \n",
    "    # make the prediction using x and theta\n",
    "    y_pred = classifier.predict(x)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def predict_tweet_prob(tweet, freqs):\n",
    "    '''\n",
    "    Input: \n",
    "        tweet: a string\n",
    "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
    "        theta: (3,1) vector of weights\n",
    "    Output: \n",
    "        y_pred: the probability of a tweet being positive or negative\n",
    "    '''\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    \n",
    "    # extract the features of the tweet and store it into x\n",
    "    x = extract_features(tweet,freqs)\n",
    "    \n",
    "    # make the prediction using x and theta\n",
    "    y_pred = classifier.predict_proba(x)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "my_tweet = 'The plot was terrible and I was sad until the ending!'\n",
    "predict_tweet(my_tweet, freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "predict_proba is not available when  probability=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-dec36730688b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msentiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_tweet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0msentiment_prob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_tweet_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-37-b475f46f7aee>\u001b[0m in \u001b[0;36mpredict_tweet_prob\u001b[1;34m(tweet, freqs)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# make the prediction using x and theta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m### END CODE HERE ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    655\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m         \"\"\"\n\u001b[1;32m--> 657\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    658\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict_proba\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_check_proba\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    622\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 624\u001b[1;33m             raise AttributeError(\"predict_proba is not available when \"\n\u001b[0m\u001b[0;32m    625\u001b[0m                                  \" probability=False\")\n\u001b[0;32m    626\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_impl\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'c_svc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'nu_svc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: predict_proba is not available when  probability=False"
     ]
    }
   ],
   "source": [
    "sentiment = []\n",
    "sentiment_prob = []\n",
    "for i in df.iloc[:,2]:\n",
    "    sentiment.append(predict_tweet(i, freqs)[0])\n",
    "    sentiment_prob.append(predict_tweet_prob(i, freqs)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['sentiment'] = sentiment\n",
    "df['sentiment_prob'] = sentiment_prob\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
