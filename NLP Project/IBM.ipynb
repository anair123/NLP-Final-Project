{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fZtC62StKAUC"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import dateutil.parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6-9soODBKAUC"
   },
   "outputs": [],
   "source": [
    "# dictionary of text dates and links (June 2020 to September 2020)\n",
    "\n",
    "date1 = '2020-07-10'\n",
    "url1 = 'https://www.reuters.com/article/us-usigrade-multiyears-idUSKBN24B2DO'\n",
    "\n",
    "date2 = '2020-07-14'\n",
    "url2 = 'https://www.reuters.com/article/us-usa-investors-gross-idUSKCN24F1EY'\n",
    "\n",
    "date3 = '2020-07-20'\n",
    "url3 = 'https://www.reuters.com/article/us-ibm-results/ibm-beats-estimates-sees-gains-as-customers-accelerate-shift-to-cloud-idUSKCN24L2L0'\n",
    "\n",
    "date4 = '2020-07-22'\n",
    "url4 = 'https://www.reuters.com/article/us-microsoft-results-idUSKCN24N2ST'\n",
    "\n",
    "date5 = '2020-08-04'\n",
    "url5 = 'https://www.reuters.com/article/usa-quantum-trump/white-house-unveils-new-partnership-to-boost-quantum-science-education-idINL1N2F70Q8'\n",
    "\n",
    "date6 = '2020-08-17'\n",
    "url6 = 'https://www.reuters.com/article/us-ibm-samsung-elec-idUSKCN25D09L'\n",
    "\n",
    "date7 = '2020-08-20'\n",
    "url7 = 'https://www.reuters.com/article/us-china-market-tech-idUSKCN25G0PU'\n",
    "\n",
    "date8 = '2020-08-26'\n",
    "url8 = 'https://www.reuters.com/article/us-usa-quantum-funding-idUSKBN25M0Y9'\n",
    "\n",
    "\n",
    "date9 = '2020-09-02'\n",
    "url9 = 'https://www.reuters.com/article/us-trump-social-media/internet-companies-urge-fcc-to-reject-trump-bid-to-impose-new-social-media-regulations-idUKKBN25T329'\n",
    "\n",
    "\n",
    "date10 = '2020-09-08'\n",
    "url10 = 'https://www.reuters.com/article/schlumberger-ibm-idUSL1N2G11I3'\n",
    "\n",
    "date11 = '2020-09-11'\n",
    "url11 = 'https://www.reuters.com/article/us-ibm-facial-recognition-exports-idUSKBN2621PV'\n",
    "\n",
    "date12 = '2020-09-16'\n",
    "url12 = 'https://in.reuters.com/article/dataprivacy-ibm-biometrics/ibm-cant-shake-facial-recognition-suit-but-dodges-some-claims-idUSL1N2GD2JP'\n",
    "\n",
    "\n",
    "date13 = '2020-10-08'\n",
    "url13 = 'https://uk.reuters.com/article/us-ibm-divestiture/ibm-to-break-up-109-year-old-company-to-focus-on-cloud-growth-idUKKBN26T1TZ'\n",
    "\n",
    "\n",
    "date14 = '2020-10-19'\n",
    "url14 = 'https://www.reuters.com/article/us-ibm-results/ibm-posts-double-digit-cloud-revenue-growth-says-customers-deferring-some-projects-idUSKBN2742QW'\n",
    "\n",
    "\n",
    "date15 = '2020-10-21'\n",
    "url15 = 'https://www.reuters.com/article/usa-stocks/us-stocks-stimulus-bets-drive-wall-street-higher-idINL4N2HB3N5'\n",
    "\n",
    "date16 = '2020-10-22'\n",
    "url16 = 'https://www.reuters.com/article/saudi-tech/saudi-arabia-signs-mous-with-ibm-alibaba-and-huawei-on-ai-idUSD5N2F800B'\n",
    "\n",
    "\n",
    "url_dict = {date1:url1,\n",
    "            date2:url2,\n",
    "            date3:url3,\n",
    "            date4:url4,\n",
    "            date5:url5,\n",
    "            date6:url6,\n",
    "            date7:url7,\n",
    "            date8:url8,\n",
    "            date9:url9,\n",
    "            date10:url10,\n",
    "            date11:url11,\n",
    "            date12:url12,\n",
    "            date13:url13,\n",
    "            date14:url14,\n",
    "            date15:url15,\n",
    "            date16:url16\n",
    "           }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8w5TfKcKKAUC",
    "outputId": "8e082e41-6d97-4007-f060-171848edba82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U.S. companies seeking capital during pandemic test bank market's new normal\n",
      "Bill Gross predicts value outperforms growth, based on rates correlation\n",
      "IBM beats estimates; sees gains as customers accelerate shift to cloud\n",
      "Microsoft cloud flagship posts first growth under 50%; bookings growth steady\n",
      "White House unveils new partnership to boost quantum science education\n",
      "IBM rolls out newest processor chip, taps Samsung for manufacturing\n",
      "In U.S.-China tech war, investors bet on China's localisation push\n",
      "U.S. to spend $625 million in five quantum information research hubs\n",
      "Internet companies urge FCC to reject Trump bid to impose new social media regulations\n",
      "Eying digital push, Schlumberger strikes cloud-computing deal with IBM\n",
      "IBM says U.S. should adopt new export controls on facial recognition systems\n",
      "IBM can't shake facial recognition suit but dodges some claims\n",
      "IBM to break up 109-year old company to focus on cloud growth\n",
      "IBM posts double-digit cloud revenue growth; says customers deferring some projects\n",
      "US STOCKS-Stimulus bets drive Wall Street higher\n",
      "Saudi Arabia signs MoUs with IBM, Alibaba and Huawei on AI\n"
     ]
    }
   ],
   "source": [
    "for key in url_dict:\n",
    "    page = requests.get(url_dict[key]).text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    print(soup.find('h1').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KBjHM0VXKAUD"
   },
   "outputs": [],
   "source": [
    "# extract info from each website and store it in dataframe\n",
    "df_text = pd.DataFrame(columns = ['Date','Header','Text'])\n",
    "header = []\n",
    "text = []\n",
    "date = []\n",
    "for key in url_dict:\n",
    "    page = requests.get(url_dict[key]).text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    date.append(datetime.strptime(key, '%Y-%m-%d').date())\n",
    "    url_header = soup.find('h1').text\n",
    "    \n",
    "    header.append(url_header)\n",
    "    url_text = soup.find('div', class_ = 'ArticleBodyWrapper').text\n",
    "    text.append(url_text)\n",
    "df_text['Date']=date\n",
    "df_text['Header']=header\n",
    "df_text['Text']=text\n",
    "\n",
    "# remove the author and \"min read\" sections\n",
    "df_text_temp = [] \n",
    "for text in df_text['Text']:\n",
    "    loc = text.find('(Reuters)')\n",
    "    df_text_temp.append(text[loc+9:])\n",
    "df_text['Text'] = df_text_temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZxYcrh5QKAUD",
    "outputId": "4c5844c8-e487-4ead-c28c-6dd810682d04"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Header</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-10</td>\n",
       "      <td>U.S. companies seeking capital during pandemic...</td>\n",
       "      <td>la  Guzman5 Min ReadNEW YORK (LPC) - Bank lend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-14</td>\n",
       "      <td>Bill Gross predicts value outperforms growth, ...</td>\n",
       "      <td>- Billionaire investor Bill Gross is predicti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-20</td>\n",
       "      <td>IBM beats estimates; sees gains as customers a...</td>\n",
       "      <td>- International Business Machines Corp IBM.N ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>Microsoft cloud flagship posts first growth un...</td>\n",
       "      <td>- Microsoft Corp's MSFT.O flagship cloud comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-04</td>\n",
       "      <td>White House unveils new partnership to boost q...</td>\n",
       "      <td>- The White House Office of Science and Techn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                                             Header  \\\n",
       "0 2020-07-10  U.S. companies seeking capital during pandemic...   \n",
       "1 2020-07-14  Bill Gross predicts value outperforms growth, ...   \n",
       "2 2020-07-20  IBM beats estimates; sees gains as customers a...   \n",
       "3 2020-07-22  Microsoft cloud flagship posts first growth un...   \n",
       "4 2020-08-04  White House unveils new partnership to boost q...   \n",
       "\n",
       "                                                Text  \n",
       "0  la  Guzman5 Min ReadNEW YORK (LPC) - Bank lend...  \n",
       "1   - Billionaire investor Bill Gross is predicti...  \n",
       "2   - International Business Machines Corp IBM.N ...  \n",
       "3   - Microsoft Corp's MSFT.O flagship cloud comp...  \n",
       "4   - The White House Office of Science and Techn...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text['Date'] = df_text['Date'].apply(lambda x: pd.to_datetime(x))\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "67t6bd5dKAUD",
    "outputId": "d9a0aa83-a081-4123-98aa-d49bf6c6f3d8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-02</td>\n",
       "      <td>134.449997</td>\n",
       "      <td>3067100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-12-03</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>3642500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-04</td>\n",
       "      <td>132.860001</td>\n",
       "      <td>3530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-05</td>\n",
       "      <td>132.990005</td>\n",
       "      <td>3595400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-06</td>\n",
       "      <td>132.750000</td>\n",
       "      <td>3437500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date        Open   Volume\n",
       "0 2019-12-02  134.449997  3067100\n",
       "1 2019-12-03  132.000000  3642500\n",
       "2 2019-12-04  132.860001  3530000\n",
       "3 2019-12-05  132.990005  3595400\n",
       "4 2019-12-06  132.750000  3437500"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import stock data of Zoom\n",
    "df_stock = pd.read_csv('IBM.csv', header=0)\n",
    "\n",
    "df_stock['Date']=df_stock['Date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))\n",
    "\n",
    "\n",
    "df_stock = df_stock.drop(['High','Low','Close','Adj Close'], axis=1)\n",
    "df_stock.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Wo351NEyKAUD",
    "outputId": "554aeeb6-1d85-4882-ad64-3724fe526291"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text['Date'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "A3u-kujoKAUE",
    "outputId": "a5c4f1ed-f142-4de4-ae73-9ce1058b2013"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stock['Date'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7ju601zuKAUE"
   },
   "outputs": [],
   "source": [
    "# Merge two dataframes\n",
    "df = pd.merge(df_text, df_stock, how='inner', on='Date')\n",
    "df = df.sort_values('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "sYybIQmGKAUE",
    "outputId": "17a47a1d-44a6-49aa-fc62-2ba150377c8a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Header</th>\n",
       "      <th>Text</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>% Change in Stock Price</th>\n",
       "      <th>% Change in Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-10</td>\n",
       "      <td>U.S. companies seeking capital during pandemic...</td>\n",
       "      <td>la  Guzman5 Min ReadNEW YORK (LPC) - Bank lend...</td>\n",
       "      <td>115.500000</td>\n",
       "      <td>4285700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-14</td>\n",
       "      <td>Bill Gross predicts value outperforms growth, ...</td>\n",
       "      <td>- Billionaire investor Bill Gross is predicti...</td>\n",
       "      <td>118.620003</td>\n",
       "      <td>4534400</td>\n",
       "      <td>2.701301</td>\n",
       "      <td>5.803019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-20</td>\n",
       "      <td>IBM beats estimates; sees gains as customers a...</td>\n",
       "      <td>- International Business Machines Corp IBM.N ...</td>\n",
       "      <td>126.070000</td>\n",
       "      <td>9927700</td>\n",
       "      <td>6.280557</td>\n",
       "      <td>118.941867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>Microsoft cloud flagship posts first growth un...</td>\n",
       "      <td>- Microsoft Corp's MSFT.O flagship cloud comp...</td>\n",
       "      <td>125.900002</td>\n",
       "      <td>8195400</td>\n",
       "      <td>-0.134844</td>\n",
       "      <td>-17.449157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-04</td>\n",
       "      <td>White House unveils new partnership to boost q...</td>\n",
       "      <td>- The White House Office of Science and Techn...</td>\n",
       "      <td>123.820000</td>\n",
       "      <td>3466100</td>\n",
       "      <td>-1.652106</td>\n",
       "      <td>-57.706762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                                             Header  \\\n",
       "0 2020-07-10  U.S. companies seeking capital during pandemic...   \n",
       "1 2020-07-14  Bill Gross predicts value outperforms growth, ...   \n",
       "2 2020-07-20  IBM beats estimates; sees gains as customers a...   \n",
       "3 2020-07-22  Microsoft cloud flagship posts first growth un...   \n",
       "4 2020-08-04  White House unveils new partnership to boost q...   \n",
       "\n",
       "                                                Text        Open   Volume  \\\n",
       "0  la  Guzman5 Min ReadNEW YORK (LPC) - Bank lend...  115.500000  4285700   \n",
       "1   - Billionaire investor Bill Gross is predicti...  118.620003  4534400   \n",
       "2   - International Business Machines Corp IBM.N ...  126.070000  9927700   \n",
       "3   - Microsoft Corp's MSFT.O flagship cloud comp...  125.900002  8195400   \n",
       "4   - The White House Office of Science and Techn...  123.820000  3466100   \n",
       "\n",
       "   % Change in Stock Price  % Change in Volume  \n",
       "0                      NaN                 NaN  \n",
       "1                 2.701301            5.803019  \n",
       "2                 6.280557          118.941867  \n",
       "3                -0.134844          -17.449157  \n",
       "4                -1.652106          -57.706762  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show % change in stock price after news article publish\n",
    "pct_stock = df['Open'].pct_change()*100\n",
    "df['% Change in Stock Price'] = pct_stock\n",
    "pct_volume = df['Volume'].pct_change()*100\n",
    "df['% Change in Volume'] = pct_volume\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HuvMBxgwKAUE"
   },
   "source": [
    "\n",
    "# Processing the text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7sg7AoKKAUE"
   },
   "source": [
    "## import spacy libraries\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "from  spacy.lang.en.stop_words import STOP_WORDS\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "XtXFYaQRKAUE"
   },
   "outputs": [],
   "source": [
    "# import spacy libraries\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "from  spacy.lang.en.stop_words import STOP_WORDS\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "03M0Se0_KAUE"
   },
   "outputs": [],
   "source": [
    "\n",
    "text_nlp = nlp(df['Text'][1]) \n",
    "# Remove stop words\n",
    "text_nlp_clean = [word for word in text_nlp if word.is_stop == False]\n",
    "# Lemmatize words\n",
    "text_nlp_clean = [word.lemma_ for word in text_nlp_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "fsqGe8igKAUE",
    "outputId": "b03cb5ef-f713-4b10-bffa-740f0c276e80"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Header</th>\n",
       "      <th>Text</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>% Change in Stock Price</th>\n",
       "      <th>% Change in Volume</th>\n",
       "      <th>Text (clean)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-10</td>\n",
       "      <td>U.S. companies seeking capital during pandemic...</td>\n",
       "      <td>la  Guzman5 Min ReadNEW YORK (LPC) - Bank lend...</td>\n",
       "      <td>115.500000</td>\n",
       "      <td>4285700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>la Guzman5 Min ReadNEW YORK LPC bank lender hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-14</td>\n",
       "      <td>Bill Gross predicts value outperforms growth, ...</td>\n",
       "      <td>- Billionaire investor Bill Gross is predicti...</td>\n",
       "      <td>118.620003</td>\n",
       "      <td>4534400</td>\n",
       "      <td>2.701301</td>\n",
       "      <td>5.803019</td>\n",
       "      <td>billionaire investor Bill Gross predict value ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-20</td>\n",
       "      <td>IBM beats estimates; sees gains as customers a...</td>\n",
       "      <td>- International Business Machines Corp IBM.N ...</td>\n",
       "      <td>126.070000</td>\n",
       "      <td>9927700</td>\n",
       "      <td>6.280557</td>\n",
       "      <td>118.941867</td>\n",
       "      <td>International Business Machines Corp IBM.N bea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>Microsoft cloud flagship posts first growth un...</td>\n",
       "      <td>- Microsoft Corp's MSFT.O flagship cloud comp...</td>\n",
       "      <td>125.900002</td>\n",
       "      <td>8195400</td>\n",
       "      <td>-0.134844</td>\n",
       "      <td>-17.449157</td>\n",
       "      <td>Microsoft Corp MSFT.O flagship cloud computing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-04</td>\n",
       "      <td>White House unveils new partnership to boost q...</td>\n",
       "      <td>- The White House Office of Science and Techn...</td>\n",
       "      <td>123.820000</td>\n",
       "      <td>3466100</td>\n",
       "      <td>-1.652106</td>\n",
       "      <td>-57.706762</td>\n",
       "      <td>White House Office Science Technology Policy s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                                             Header  \\\n",
       "0 2020-07-10  U.S. companies seeking capital during pandemic...   \n",
       "1 2020-07-14  Bill Gross predicts value outperforms growth, ...   \n",
       "2 2020-07-20  IBM beats estimates; sees gains as customers a...   \n",
       "3 2020-07-22  Microsoft cloud flagship posts first growth un...   \n",
       "4 2020-08-04  White House unveils new partnership to boost q...   \n",
       "\n",
       "                                                Text        Open   Volume  \\\n",
       "0  la  Guzman5 Min ReadNEW YORK (LPC) - Bank lend...  115.500000  4285700   \n",
       "1   - Billionaire investor Bill Gross is predicti...  118.620003  4534400   \n",
       "2   - International Business Machines Corp IBM.N ...  126.070000  9927700   \n",
       "3   - Microsoft Corp's MSFT.O flagship cloud comp...  125.900002  8195400   \n",
       "4   - The White House Office of Science and Techn...  123.820000  3466100   \n",
       "\n",
       "   % Change in Stock Price  % Change in Volume  \\\n",
       "0                      NaN                 NaN   \n",
       "1                 2.701301            5.803019   \n",
       "2                 6.280557          118.941867   \n",
       "3                -0.134844          -17.449157   \n",
       "4                -1.652106          -57.706762   \n",
       "\n",
       "                                        Text (clean)  \n",
       "0  la Guzman5 Min ReadNEW YORK LPC bank lender hi...  \n",
       "1  billionaire investor Bill Gross predict value ...  \n",
       "2  International Business Machines Corp IBM.N bea...  \n",
       "3  Microsoft Corp MSFT.O flagship cloud computing...  \n",
       "4  White House Office Science Technology Policy s...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clean = []\n",
    "for ind, row in df.iterrows():\n",
    "    \n",
    "    # lower casing\n",
    "    text_lower = row['Text'].lower()\n",
    "    \n",
    "    # tokenization\n",
    "    text_nlp = nlp(row['Text']) \n",
    "    \n",
    "    # remove punctuation and empty space\n",
    "    text_nlp_clean = [word for word in text_nlp if not word.is_punct | word.is_space]\n",
    "    \n",
    "    # Remove stop words\n",
    "    text_nlp_clean = [word for word in text_nlp_clean if word.is_stop == False]\n",
    "    \n",
    "    # Lemmatize tokens\n",
    "    text_nlp_clean = [word.lemma_ for word in text_nlp_clean]\n",
    "    \n",
    "    # add preprocessed text to list\n",
    "    text_clean.append(text_nlp_clean)\n",
    "\n",
    "# turn list of strings to string\n",
    "to_string = []\n",
    "for text in text_clean:\n",
    "    to_string.append(' '.join(text))\n",
    "\n",
    "\n",
    "df['Text (clean)'] = to_string\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFkZmAHpKAUE"
   },
   "source": [
    "# Using a Pretrained Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "MyGLDr7NKAUE"
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "UbC1BKVsKAUE"
   },
   "outputs": [],
   "source": [
    "# a function to return sentiment score\n",
    "def polarity_score(text):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    return sid.polarity_scores(text)['compound']\n",
    "\n",
    "vader_score = []\n",
    "for text in df['Text (clean)']:\n",
    "    score = polarity_score(text)\n",
    "    vader_score.append(score)\n",
    "\n",
    "df['Vader Sentiment Score'] = vader_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "dJhGvHxgKAUE",
    "outputId": "be2df9be-5856-4172-d51c-5abacf8a959c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Header</th>\n",
       "      <th>Text</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>% Change in Stock Price</th>\n",
       "      <th>% Change in Volume</th>\n",
       "      <th>Text (clean)</th>\n",
       "      <th>Vader Sentiment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-10</td>\n",
       "      <td>U.S. companies seeking capital during pandemic...</td>\n",
       "      <td>la  Guzman5 Min ReadNEW YORK (LPC) - Bank lend...</td>\n",
       "      <td>115.500000</td>\n",
       "      <td>4285700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>la Guzman5 Min ReadNEW YORK LPC bank lender hi...</td>\n",
       "      <td>0.9963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-14</td>\n",
       "      <td>Bill Gross predicts value outperforms growth, ...</td>\n",
       "      <td>- Billionaire investor Bill Gross is predicti...</td>\n",
       "      <td>118.620003</td>\n",
       "      <td>4534400</td>\n",
       "      <td>2.701301</td>\n",
       "      <td>5.803019</td>\n",
       "      <td>billionaire investor Bill Gross predict value ...</td>\n",
       "      <td>0.9831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-20</td>\n",
       "      <td>IBM beats estimates; sees gains as customers a...</td>\n",
       "      <td>- International Business Machines Corp IBM.N ...</td>\n",
       "      <td>126.070000</td>\n",
       "      <td>9927700</td>\n",
       "      <td>6.280557</td>\n",
       "      <td>118.941867</td>\n",
       "      <td>International Business Machines Corp IBM.N bea...</td>\n",
       "      <td>0.8020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>Microsoft cloud flagship posts first growth un...</td>\n",
       "      <td>- Microsoft Corp's MSFT.O flagship cloud comp...</td>\n",
       "      <td>125.900002</td>\n",
       "      <td>8195400</td>\n",
       "      <td>-0.134844</td>\n",
       "      <td>-17.449157</td>\n",
       "      <td>Microsoft Corp MSFT.O flagship cloud computing...</td>\n",
       "      <td>0.9849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-04</td>\n",
       "      <td>White House unveils new partnership to boost q...</td>\n",
       "      <td>- The White House Office of Science and Techn...</td>\n",
       "      <td>123.820000</td>\n",
       "      <td>3466100</td>\n",
       "      <td>-1.652106</td>\n",
       "      <td>-57.706762</td>\n",
       "      <td>White House Office Science Technology Policy s...</td>\n",
       "      <td>0.9100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                                             Header  \\\n",
       "0 2020-07-10  U.S. companies seeking capital during pandemic...   \n",
       "1 2020-07-14  Bill Gross predicts value outperforms growth, ...   \n",
       "2 2020-07-20  IBM beats estimates; sees gains as customers a...   \n",
       "3 2020-07-22  Microsoft cloud flagship posts first growth un...   \n",
       "4 2020-08-04  White House unveils new partnership to boost q...   \n",
       "\n",
       "                                                Text        Open   Volume  \\\n",
       "0  la  Guzman5 Min ReadNEW YORK (LPC) - Bank lend...  115.500000  4285700   \n",
       "1   - Billionaire investor Bill Gross is predicti...  118.620003  4534400   \n",
       "2   - International Business Machines Corp IBM.N ...  126.070000  9927700   \n",
       "3   - Microsoft Corp's MSFT.O flagship cloud comp...  125.900002  8195400   \n",
       "4   - The White House Office of Science and Techn...  123.820000  3466100   \n",
       "\n",
       "   % Change in Stock Price  % Change in Volume  \\\n",
       "0                      NaN                 NaN   \n",
       "1                 2.701301            5.803019   \n",
       "2                 6.280557          118.941867   \n",
       "3                -0.134844          -17.449157   \n",
       "4                -1.652106          -57.706762   \n",
       "\n",
       "                                        Text (clean)  Vader Sentiment Score  \n",
       "0  la Guzman5 Min ReadNEW YORK LPC bank lender hi...                 0.9963  \n",
       "1  billionaire investor Bill Gross predict value ...                 0.9831  \n",
       "2  International Business Machines Corp IBM.N bea...                 0.8020  \n",
       "3  Microsoft Corp MSFT.O flagship cloud computing...                 0.9849  \n",
       "4  White House Office Science Technology Policy s...                 0.9100  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LkZS4-bPKAUE"
   },
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "FvdSV61lKAUE"
   },
   "outputs": [],
   "source": [
    "# run this cell to import nltk\n",
    "import nltk\n",
    "from os import getcwd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import twitter_samples \n",
    "from utils import process_tweet, build_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "mX42Hu77KAUE",
    "outputId": "c9be7a9d-5a11-464e-a055-4d425f88a684"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\aashi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aashi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('twitter_samples')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "92mXvGeHKAUE"
   },
   "outputs": [],
   "source": [
    "\n",
    "# select the set of positive and negative tweets\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "nMMDGQ75KAUE"
   },
   "outputs": [],
   "source": [
    "# split the data into two pieces (80-20), one for training and one for testing (validation set)  \n",
    "test_pos = all_positive_tweets[4000:]\n",
    "train_pos = all_positive_tweets[:4000]\n",
    "test_neg = all_negative_tweets[4000:]\n",
    "train_neg = all_negative_tweets[:4000]\n",
    "\n",
    "train_x = train_pos + train_neg \n",
    "test_x = test_pos + test_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ZXLAsWueKAUE"
   },
   "outputs": [],
   "source": [
    "# combine positive and negative labels\n",
    "train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n",
    "test_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "1hjdljIOKAUE",
    "outputId": "c2f9f025-cb73-447a-d996-a4f65dd8e3f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_y.shape = (8000, 1)\n",
      "test_y.shape = (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape train and test sets\n",
    "print(\"train_y.shape = \" + str(train_y.shape))\n",
    "print(\"test_y.shape = \" + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "aIIUFWCIKAUE",
    "outputId": "1794dd11-2385-44b5-cca0-7d1f7e968b11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(freqs) = <class 'dict'>\n",
      "len(freqs) = 11340\n"
     ]
    }
   ],
   "source": [
    "# create frequency dictionary\n",
    "freqs = build_freqs(train_x, train_y)\n",
    "\n",
    "# check the output\n",
    "print(\"type(freqs) = \" + str(type(freqs)))\n",
    "print(\"len(freqs) = \" + str(len(freqs.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "npWKnGgQKAUF"
   },
   "outputs": [],
   "source": [
    "# UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def extract_features(tweet, freqs):\n",
    "    '''\n",
    "    Input: \n",
    "        tweet: a list of words for one tweet\n",
    "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
    "    Output: \n",
    "        x: a feature vector of dimension (1,3)\n",
    "    '''\n",
    "    # process_tweet tokenizes, stems, and removes stopwords\n",
    "    word_l = process_tweet(tweet)\n",
    "    \n",
    "    # 3 elements in the form of a 1 x 3 vector\n",
    "    x = np.zeros((1, 3)) \n",
    "    \n",
    "    #bias term is set to 1\n",
    "    x[0,0] = 1 \n",
    "    \n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    \n",
    "    # loop through each word in the list of words\n",
    "    for word in word_l:\n",
    "        \n",
    "        # increment the word count for the positive label 1\n",
    "        \n",
    "        x[0,1] += freqs.get((word,1),0)\n",
    "        \n",
    "        # increment the word count for the negative label 0\n",
    "        x[0,2] += freqs.get((word,0),0)\n",
    "        \n",
    "    ### END CODE HERE ###\n",
    "    assert(x.shape == (1, 3))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "dxSR4HEvKAUF"
   },
   "outputs": [],
   "source": [
    "# collect the features 'x' and stack them into a matrix 'X'\n",
    "X = np.zeros((len(train_x), 3))\n",
    "for i in range(len(train_x)):\n",
    "    X[i, :]= extract_features(train_x[i], freqs)\n",
    "\n",
    "# training labels corresponding to X\n",
    "Y = train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "2YKi_T3oKAUF",
    "outputId": "1f31b4d9-038c-4c89-cf75-9a52a2875800"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3FLQ0pMKAUF"
   },
   "source": [
    "### SVM Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "5jL-Py2oKAUF",
    "outputId": "ce6549b5-085e-4c79-9c4d-178a08017417"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aashi\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Logistic Regression to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "a2t6OnL8KAUF"
   },
   "outputs": [],
   "source": [
    "\n",
    "# UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def predict_tweet(tweet, freqs):\n",
    "    '''\n",
    "    Input: \n",
    "        tweet: a string\n",
    "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
    "        theta: (3,1) vector of weights\n",
    "    Output: \n",
    "        y_pred: the probability of a tweet being positive or negative\n",
    "    '''\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    \n",
    "    # extract the features of the tweet and store it into x\n",
    "    x = extract_features(tweet,freqs)\n",
    "    \n",
    "    # make the prediction using x and theta\n",
    "    y_pred = classifier.predict(x)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "eRD5jfpzKAUF"
   },
   "outputs": [],
   "source": [
    "# UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def predict_tweet_prob(tweet, freqs):\n",
    "    '''\n",
    "    Input: \n",
    "        tweet: a string\n",
    "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
    "        theta: (3,1) vector of weights\n",
    "    Output: \n",
    "        y_pred: the probability of a tweet being positive or negative\n",
    "    '''\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    \n",
    "    # extract the features of the tweet and store it into x\n",
    "    x = extract_features(tweet,freqs)\n",
    "    \n",
    "    # make the prediction using x and theta\n",
    "    y_pred = classifier.predict_proba(x)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "sHbpi3sOKAUF",
    "outputId": "43056f9a-e782-465d-e820-c03cdaffdee2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "my_tweet = 'The plot was terrible and I was sad until the ending!'\n",
    "predict_tweet(my_tweet, freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = []\n",
    "sentiment_prob = []\n",
    "for i in df.iloc[:,2]:\n",
    "    sentiment.append(predict_tweet(i, freqs)[0])\n",
    "    sentiment_prob.append(predict_tweet_prob(i, freqs)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Header</th>\n",
       "      <th>Text</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>% Change in Stock Price</th>\n",
       "      <th>% Change in Volume</th>\n",
       "      <th>Text (clean)</th>\n",
       "      <th>Vader Sentiment Score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-10</td>\n",
       "      <td>U.S. companies seeking capital during pandemic...</td>\n",
       "      <td>la  Guzman5 Min ReadNEW YORK (LPC) - Bank lend...</td>\n",
       "      <td>115.500000</td>\n",
       "      <td>4285700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>la Guzman5 Min ReadNEW YORK LPC bank lender hi...</td>\n",
       "      <td>0.9963</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.987249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-14</td>\n",
       "      <td>Bill Gross predicts value outperforms growth, ...</td>\n",
       "      <td>- Billionaire investor Bill Gross is predicti...</td>\n",
       "      <td>118.620003</td>\n",
       "      <td>4534400</td>\n",
       "      <td>2.701301</td>\n",
       "      <td>5.803019</td>\n",
       "      <td>billionaire investor Bill Gross predict value ...</td>\n",
       "      <td>0.9831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.415353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-20</td>\n",
       "      <td>IBM beats estimates; sees gains as customers a...</td>\n",
       "      <td>- International Business Machines Corp IBM.N ...</td>\n",
       "      <td>126.070000</td>\n",
       "      <td>9927700</td>\n",
       "      <td>6.280557</td>\n",
       "      <td>118.941867</td>\n",
       "      <td>International Business Machines Corp IBM.N bea...</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.110248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>Microsoft cloud flagship posts first growth un...</td>\n",
       "      <td>- Microsoft Corp's MSFT.O flagship cloud comp...</td>\n",
       "      <td>125.900002</td>\n",
       "      <td>8195400</td>\n",
       "      <td>-0.134844</td>\n",
       "      <td>-17.449157</td>\n",
       "      <td>Microsoft Corp MSFT.O flagship cloud computing...</td>\n",
       "      <td>0.9849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-04</td>\n",
       "      <td>White House unveils new partnership to boost q...</td>\n",
       "      <td>- The White House Office of Science and Techn...</td>\n",
       "      <td>123.820000</td>\n",
       "      <td>3466100</td>\n",
       "      <td>-1.652106</td>\n",
       "      <td>-57.706762</td>\n",
       "      <td>White House Office Science Technology Policy s...</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.707602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                                             Header  \\\n",
       "0 2020-07-10  U.S. companies seeking capital during pandemic...   \n",
       "1 2020-07-14  Bill Gross predicts value outperforms growth, ...   \n",
       "2 2020-07-20  IBM beats estimates; sees gains as customers a...   \n",
       "3 2020-07-22  Microsoft cloud flagship posts first growth un...   \n",
       "4 2020-08-04  White House unveils new partnership to boost q...   \n",
       "\n",
       "                                                Text        Open   Volume  \\\n",
       "0  la  Guzman5 Min ReadNEW YORK (LPC) - Bank lend...  115.500000  4285700   \n",
       "1   - Billionaire investor Bill Gross is predicti...  118.620003  4534400   \n",
       "2   - International Business Machines Corp IBM.N ...  126.070000  9927700   \n",
       "3   - Microsoft Corp's MSFT.O flagship cloud comp...  125.900002  8195400   \n",
       "4   - The White House Office of Science and Techn...  123.820000  3466100   \n",
       "\n",
       "   % Change in Stock Price  % Change in Volume  \\\n",
       "0                      NaN                 NaN   \n",
       "1                 2.701301            5.803019   \n",
       "2                 6.280557          118.941867   \n",
       "3                -0.134844          -17.449157   \n",
       "4                -1.652106          -57.706762   \n",
       "\n",
       "                                        Text (clean)  Vader Sentiment Score  \\\n",
       "0  la Guzman5 Min ReadNEW YORK LPC bank lender hi...                 0.9963   \n",
       "1  billionaire investor Bill Gross predict value ...                 0.9831   \n",
       "2  International Business Machines Corp IBM.N bea...                 0.8020   \n",
       "3  Microsoft Corp MSFT.O flagship cloud computing...                 0.9849   \n",
       "4  White House Office Science Technology Policy s...                 0.9100   \n",
       "\n",
       "   sentiment  sentiment_prob  \n",
       "0        1.0        0.987249  \n",
       "1        0.0        0.415353  \n",
       "2        0.0        0.110248  \n",
       "3        0.0        0.011837  \n",
       "4        1.0        0.707602  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'] = sentiment\n",
    "df['sentiment_prob'] = sentiment_prob\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZFEPU2mKIDD"
   },
   "source": [
    "# START OF DEEP LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "85yFtJzFKCny"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aashi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\aashi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\aashi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\aashi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\aashi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\aashi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\aashi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aashi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import sklearn.metrics\n",
    "import tensorflow as tf\n",
    "from scipy.special import softmax\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "import torch\n",
    "import torchtext\n",
    "import torchtext.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from scipy.special import softmax\n",
    "from torchtext.vocab import Vocab\n",
    "from nltk.corpus import twitter_samples \n",
    "\n",
    "nlp = spacy.load('en')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "yPSzmuAbKD3K"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aashi\\Anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "edd7m2cOKERb"
   },
   "outputs": [],
   "source": [
    "# %% ----------------------------------- Hyper Parameters --------------------------------------------------------------\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.seq_len = \"get_max_from_data\"\n",
    "        self.embedding_dim = 50\n",
    "        self.n_epochs = 10\n",
    "        self.lr = 1e-2\n",
    "        self.batch_size = 512\n",
    "        self.train = True\n",
    "        self.save_model = True\n",
    "\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "0ORR7LJSKED7"
   },
   "outputs": [],
   "source": [
    "# %% ----------------------------------- Helper Functions --------------------------------------------------------------\n",
    "def acc(x, y, return_labels=False):\n",
    "    with torch.no_grad():\n",
    "        logits = torch.empty(len(x), 2)\n",
    "        for batch in range(len(x) // args.batch_size + 1):\n",
    "            inds = slice(batch * args.batch_size, (batch + 1) * args.batch_size)\n",
    "            logits[inds] = model(x[inds])\n",
    "        pred_labels = np.argmax(logits.cpu().numpy(), axis=1)\n",
    "    if return_labels:\n",
    "        return pred_labels\n",
    "    else:\n",
    "        return 100*accuracy_score(y.cpu().numpy(), pred_labels)\n",
    "\n",
    "\n",
    "def extract_vocab_dict_and_msl(sentences_train, sentences_dev):\n",
    "    \"\"\" Tokenizes all the sentences and gets a dictionary of unique tokens and also the maximum sequence length \"\"\"\n",
    "    tokens, ms_len = [], 0\n",
    "    for sentence in list(sentences_train) + list(sentences_dev):\n",
    "        tokens_in_sentence = nltk.word_tokenize(sentence)\n",
    "        if ms_len < len(tokens_in_sentence):\n",
    "            ms_len = len(tokens_in_sentence)\n",
    "        tokens += tokens_in_sentence\n",
    "    token_vocab = {key: i for key, i in zip(set(tokens), range(1, len(set(tokens))+1))}\n",
    "    if len(np.unique(list(token_vocab.values()))) != len(token_vocab):\n",
    "        \"There are some rep words...\"\n",
    "    return token_vocab, ms_len\n",
    "\n",
    "\n",
    "def convert_to_ids(raw_sentences, vocab_dict, pad_to):\n",
    "    \"\"\" Takes an NumPy array of raw text sentences and converts to a sequence of token ids \"\"\"\n",
    "    x = np.empty((len(raw_sentences), pad_to))\n",
    "    for idx, sentence in enumerate(raw_sentences):\n",
    "        word_ids = []\n",
    "        for token in nltk.word_tokenize(sentence):\n",
    "            try:\n",
    "                word_ids.append(vocab_dict[token])\n",
    "            except:\n",
    "                word_ids.append(vocab_dict[token])\n",
    "        if pad_to < len(word_ids):\n",
    "            x[idx] = word_ids[:pad_to]\n",
    "        else:\n",
    "            x[idx] = word_ids + [0] * (pad_to - len(word_ids))\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_glove_embeddings(vocab_dict):\n",
    "    with open(\"glove.6B.50d.txt\", \"r\") as s:\n",
    "        glove = s.read()\n",
    "    embeddings_dict = {}\n",
    "    for line in glove.split(\"\\n\")[:-1]:\n",
    "        text = line.split()\n",
    "        if text[0] in vocab_dict:\n",
    "            embeddings_dict[vocab_dict[text[0]]] = torch.from_numpy(np.array(text[1:], dtype=\"float32\"))\n",
    "    return embeddings_dict\n",
    "\n",
    "\n",
    "def get_glove_table(vocab_dict, glove_dict):\n",
    "    lookup_table = torch.empty((len(vocab_dict)+2, 50))\n",
    "    for token_id in sorted(vocab_dict.values()):\n",
    "        if token_id in glove_dict:\n",
    "            lookup_table[token_id] = glove_dict[token_id]\n",
    "        else:\n",
    "            lookup_table[token_id] = torch.zeros((1, 50))  # For unknown tokens\n",
    "    lookup_table[0] = torch.zeros((1, 50))\n",
    "    return lookup_table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "qxRkhvHCKDq6"
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"original_data/train.tsv\", sep=\"\\t\")\n",
    "x_train_raw, y_train = data_train[\"sentence\"].values, torch.LongTensor(data_train[\"label\"].values).to(device)\n",
    "data_dev = pd.read_csv(\"original_data/dev.tsv\", sep=\"\\t\")\n",
    "x_dev_raw, y_dev = data_dev[\"sentence\"].values, torch.LongTensor(data_dev[\"label\"].values).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "QygYJtQXKQgP"
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x9d in position 608481: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-8c307080a985>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmsl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mglove_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_glove_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-c48b10f5ef25>\u001b[0m in \u001b[0;36mget_glove_embeddings\u001b[1;34m(vocab_dict)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_glove_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"glove.6B.50d.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mglove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m     \u001b[0membeddings_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglove\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x9d in position 608481: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "# %% -------------------------------------- Data Prep ------------------------------------------------------------------\n",
    "try:\n",
    "    with open(\"example_prep_data/vocab_dict.json\", \"r\") as s:\n",
    "        token_ids = json.load(s)\n",
    "    msl = np.load(\"example_prep_data/max_sequence_length.npy\").item()\n",
    "except:\n",
    "    print(\"Tokenizing all the examples to get a vocab dict and the maximum sequence length...\")\n",
    "    token_ids, msl = extract_vocab_dict_and_msl(x_train_raw, x_dev_raw)\n",
    "    os.mkdir(\"example_prep_data\")\n",
    "    with open(\"example_prep_data/vocab_dict.json\", \"w\") as s:\n",
    "        json.dump(token_ids, s)\n",
    "    np.save(\"example_prep_data/max_sequence_length.npy\", np.array([msl]))\n",
    "if args.seq_len == \"get_max_from_data\":\n",
    "    args.seq_len = msl\n",
    "\n",
    "glove_embeddings = get_glove_embeddings(token_ids)\n",
    "\n",
    "try:\n",
    "    x_train = np.load(\"example_prep_data/prep_train_len{}.npy\".format(args.seq_len))\n",
    "    x_dev = np.load(\"example_prep_data/prep_dev_len{}.npy\".format(args.seq_len))\n",
    "except:\n",
    "    print(\"Converting all the sentences to sequences of token ids...\")\n",
    "    x_train = convert_to_ids(x_train_raw, token_ids, args.seq_len)\n",
    "    np.save(\"example_prep_data/prep_train_len{}.npy\".format(args.seq_len), x_train)\n",
    "    x_dev = convert_to_ids(x_dev_raw, token_ids, args.seq_len)\n",
    "    np.save(\"example_prep_data/prep_dev_len{}.npy\".format(args.seq_len), x_dev)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "StiU3dvfKQsh"
   },
   "outputs": [],
   "source": [
    "x_train, x_dev = torch.LongTensor(x_train).to(device), torch.LongTensor(x_dev).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-SWQOKIwKQ29"
   },
   "outputs": [],
   "source": [
    "# %% -------------------------------------- CNN Class ------------------------------------------------------------------\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size + 2, args.embedding_dim)\n",
    "\n",
    "        self.conv1 = nn.Conv1d(args.embedding_dim, args.embedding_dim, 9)\n",
    "        self.convnorm1 = nn.BatchNorm1d(args.embedding_dim)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(args.embedding_dim, args.embedding_dim, 9)\n",
    "        self.convnorm2 = nn.BatchNorm1d(args.embedding_dim)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(args.embedding_dim, args.embedding_dim, 7)\n",
    "        self.linear = nn.Linear(args.embedding_dim, 2)\n",
    "        self.act = torch.relu\n",
    "\n",
    "    def forward(self, x):\n",
    "        # nn.Conv1d operates on the columns, each embedding dimension is considered as one channel\n",
    "        x = self.embedding(x).permute(0, 2, 1)\n",
    "        x = self.pool1(self.convnorm1(self.act(self.conv1(x))))\n",
    "        x = self.pool2(self.convnorm2(self.act(self.conv2(x))))\n",
    "        return self.linear(self.act(self.conv3(x)).reshape(-1, args.embedding_dim))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k6kcA-u1KRBO"
   },
   "outputs": [],
   "source": [
    "# %% -------------------------------------- Training Prep ----------------------------------------------------------\n",
    "model = CNN(len(token_ids)).to(device)\n",
    "look_up_table = get_glove_table(token_ids, glove_embeddings)\n",
    "model.embedding.weight.data.copy_(look_up_table)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1fuM7L-dKQ8F"
   },
   "outputs": [],
   "source": [
    "# %% -------------------------------------- Training Loop ----------------------------------------------------------\n",
    "labels_ditrib = torch.unique(y_dev, return_counts=True)\n",
    "print(\"The no information rate is {:.2f}\".format(100*labels_ditrib[1].max().item()/len(y_dev)))\n",
    "if args.train:\n",
    "    acc_dev_best = 0\n",
    "    print(\"Starting training loop...\")\n",
    "    for epoch in range(args.n_epochs):\n",
    "\n",
    "        loss_train, train_steps = 0, 0\n",
    "        model.train()\n",
    "        total = len(x_train) // args.batch_size + 1  # Initiates a progress bar that will be updated for each batch\n",
    "        with tqdm(total=total, desc=\"Epoch {}\".format(epoch)) as pbar:  # \"Epoch\" will be updated for each epoch\n",
    "            for batch in range(len(x_train)//args.batch_size + 1):\n",
    "                inds = slice(batch*args.batch_size, (batch+1)*args.batch_size)\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(x_train[inds])\n",
    "                loss = criterion(logits, y_train[inds])\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loss_train += loss.item()\n",
    "                train_steps += 1\n",
    "                pbar.update(1)  # Updates the progress and the training loss\n",
    "                pbar.set_postfix_str(\"Training Loss: {:.5f}\".format(loss_train / train_steps))\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_dev_pred = model(x_dev)\n",
    "            loss = criterion(y_dev_pred, y_dev)\n",
    "            loss_test = loss.item()\n",
    "\n",
    "        acc_dev = acc(x_dev, y_dev)\n",
    "        print(\"Epoch {} | Train Loss {:.5f}, Train Acc {:.2f} - Test Loss {:.5f}, Test Acc {:.2f}\".format(\n",
    "            epoch, loss_train/train_steps, acc(x_train, y_train), loss_test, acc_dev))\n",
    "\n",
    "        if acc_dev > acc_dev_best and args.save_model:\n",
    "            torch.save(model.state_dict(), \"cnn_sentiment.pt\")\n",
    "            print(\"The model has been saved!\")\n",
    "            acc_dev_best = acc_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVLMfgsAKjct"
   },
   "source": [
    "# Test of Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v2G45WKUKQyq"
   },
   "outputs": [],
   "source": [
    "x = None\n",
    "for i in range(10):\n",
    "    test = convert_to_ids([x_train_raw[i]], token_ids, args.seq_len)\n",
    "    test = torch.LongTensor(test).to(device)\n",
    "    pred = model(test).cpu().detach().numpy()[0]\n",
    "    x = softmax(pred)\n",
    "    print(softmax(pred),y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cQfsUv9DKQkP"
   },
   "outputs": [],
   "source": [
    "\n",
    "x = None\n",
    "deep_learning_sentiment_prob = []\n",
    "\n",
    "for i in df.iloc[:,2]:\n",
    "    test = convert_to_ids([i], token_ids, args.seq_len)\n",
    "    test = torch.LongTensor(test).to(device)\n",
    "    pred = model(test).cpu().detach().numpy()[0]\n",
    "    x = softmax(pred)\n",
    "    sentiment_prob.append(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gr3j1xrQKQbB"
   },
   "outputs": [],
   "source": [
    "df['deep_learning_sentiment_prob'] = sentiment_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tcTS6NmsVs8F"
   },
   "source": [
    "#END OF DEEP LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WF63pXtRKAUF"
   },
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Mw9r9U5AKAUG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 6, 2, 13, 13, 3, 6, 7, 6, 3, 5, 22, 11, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "# Converting % stock price change to % stock price change per day\n",
    "days = [0]\n",
    "for i in range(len(df['Date'])):\n",
    "    if i != 0:\n",
    "        date_diff = df['Date'][i]-df['Date'][i-1]\n",
    "        day = date_diff.days\n",
    "        days.append(day)\n",
    "print(days)\n",
    "df['Days Elapsed'] = days\n",
    "df.head()\n",
    "df['% Change in Stock Price Per Day'] = df['% Change in Stock Price']/df['Days Elapsed']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "FmTAjo2ZKAUG"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Header</th>\n",
       "      <th>Text</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>% Change in Stock Price</th>\n",
       "      <th>% Change in Volume</th>\n",
       "      <th>Text (clean)</th>\n",
       "      <th>Vader Sentiment Score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_prob</th>\n",
       "      <th>Days Elapsed</th>\n",
       "      <th>% Change in Stock Price Per Day</th>\n",
       "      <th>Vader Sentiment</th>\n",
       "      <th>Logistic Regression Sentiment</th>\n",
       "      <th>Stock Price Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-10</td>\n",
       "      <td>U.S. companies seeking capital during pandemic...</td>\n",
       "      <td>la  Guzman5 Min ReadNEW YORK (LPC) - Bank lend...</td>\n",
       "      <td>115.500000</td>\n",
       "      <td>4285700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>la Guzman5 Min ReadNEW YORK LPC bank lender hi...</td>\n",
       "      <td>0.9963</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.987249</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-14</td>\n",
       "      <td>Bill Gross predicts value outperforms growth, ...</td>\n",
       "      <td>- Billionaire investor Bill Gross is predicti...</td>\n",
       "      <td>118.620003</td>\n",
       "      <td>4534400</td>\n",
       "      <td>2.701301</td>\n",
       "      <td>5.803019</td>\n",
       "      <td>billionaire investor Bill Gross predict value ...</td>\n",
       "      <td>0.9831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.415353</td>\n",
       "      <td>4</td>\n",
       "      <td>0.675325</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-20</td>\n",
       "      <td>IBM beats estimates; sees gains as customers a...</td>\n",
       "      <td>- International Business Machines Corp IBM.N ...</td>\n",
       "      <td>126.070000</td>\n",
       "      <td>9927700</td>\n",
       "      <td>6.280557</td>\n",
       "      <td>118.941867</td>\n",
       "      <td>International Business Machines Corp IBM.N bea...</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.110248</td>\n",
       "      <td>6</td>\n",
       "      <td>1.046760</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>Microsoft cloud flagship posts first growth un...</td>\n",
       "      <td>- Microsoft Corp's MSFT.O flagship cloud comp...</td>\n",
       "      <td>125.900002</td>\n",
       "      <td>8195400</td>\n",
       "      <td>-0.134844</td>\n",
       "      <td>-17.449157</td>\n",
       "      <td>Microsoft Corp MSFT.O flagship cloud computing...</td>\n",
       "      <td>0.9849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011837</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.067422</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-04</td>\n",
       "      <td>White House unveils new partnership to boost q...</td>\n",
       "      <td>- The White House Office of Science and Techn...</td>\n",
       "      <td>123.820000</td>\n",
       "      <td>3466100</td>\n",
       "      <td>-1.652106</td>\n",
       "      <td>-57.706762</td>\n",
       "      <td>White House Office Science Technology Policy s...</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.127085</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                                             Header  \\\n",
       "0 2020-07-10  U.S. companies seeking capital during pandemic...   \n",
       "1 2020-07-14  Bill Gross predicts value outperforms growth, ...   \n",
       "2 2020-07-20  IBM beats estimates; sees gains as customers a...   \n",
       "3 2020-07-22  Microsoft cloud flagship posts first growth un...   \n",
       "4 2020-08-04  White House unveils new partnership to boost q...   \n",
       "\n",
       "                                                Text        Open   Volume  \\\n",
       "0  la  Guzman5 Min ReadNEW YORK (LPC) - Bank lend...  115.500000  4285700   \n",
       "1   - Billionaire investor Bill Gross is predicti...  118.620003  4534400   \n",
       "2   - International Business Machines Corp IBM.N ...  126.070000  9927700   \n",
       "3   - Microsoft Corp's MSFT.O flagship cloud comp...  125.900002  8195400   \n",
       "4   - The White House Office of Science and Techn...  123.820000  3466100   \n",
       "\n",
       "   % Change in Stock Price  % Change in Volume  \\\n",
       "0                      NaN                 NaN   \n",
       "1                 2.701301            5.803019   \n",
       "2                 6.280557          118.941867   \n",
       "3                -0.134844          -17.449157   \n",
       "4                -1.652106          -57.706762   \n",
       "\n",
       "                                        Text (clean)  Vader Sentiment Score  \\\n",
       "0  la Guzman5 Min ReadNEW YORK LPC bank lender hi...                 0.9963   \n",
       "1  billionaire investor Bill Gross predict value ...                 0.9831   \n",
       "2  International Business Machines Corp IBM.N bea...                 0.8020   \n",
       "3  Microsoft Corp MSFT.O flagship cloud computing...                 0.9849   \n",
       "4  White House Office Science Technology Policy s...                 0.9100   \n",
       "\n",
       "   sentiment  sentiment_prob  Days Elapsed  % Change in Stock Price Per Day  \\\n",
       "0        1.0        0.987249             0                              NaN   \n",
       "1        0.0        0.415353             4                         0.675325   \n",
       "2        0.0        0.110248             6                         1.046760   \n",
       "3        0.0        0.011837             2                        -0.067422   \n",
       "4        1.0        0.707602            13                        -0.127085   \n",
       "\n",
       "  Vader Sentiment Logistic Regression Sentiment Stock Price Change  \n",
       "0        positive                      positive           negative  \n",
       "1        positive                      negative           positive  \n",
       "2        positive                      negative           positive  \n",
       "3        positive                      negative           negative  \n",
       "4        positive                      positive           negative  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Vader Sentiment'] = df['Vader Sentiment Score'].apply(lambda x: \"positive\" if x>0 else \"negative\")\n",
    "df['Logistic Regression Sentiment'] = df['sentiment_prob'].apply(lambda x: \"positive\" if x>0.5 else \"negative\")\n",
    "df['Stock Price Change'] = df['% Change in Stock Price Per Day'].apply(lambda x: \"positive\" if x>0 else \"negative\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Header</th>\n",
       "      <th>Stock Price Change</th>\n",
       "      <th>Vader Sentiment</th>\n",
       "      <th>Logistic Regression Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-10</td>\n",
       "      <td>U.S. companies seeking capital during pandemic...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-14</td>\n",
       "      <td>Bill Gross predicts value outperforms growth, ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-20</td>\n",
       "      <td>IBM beats estimates; sees gains as customers a...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>Microsoft cloud flagship posts first growth un...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-04</td>\n",
       "      <td>White House unveils new partnership to boost q...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                                             Header  \\\n",
       "0 2020-07-10  U.S. companies seeking capital during pandemic...   \n",
       "1 2020-07-14  Bill Gross predicts value outperforms growth, ...   \n",
       "2 2020-07-20  IBM beats estimates; sees gains as customers a...   \n",
       "3 2020-07-22  Microsoft cloud flagship posts first growth un...   \n",
       "4 2020-08-04  White House unveils new partnership to boost q...   \n",
       "\n",
       "  Stock Price Change Vader Sentiment Logistic Regression Sentiment  \n",
       "0           negative        positive                      positive  \n",
       "1           positive        positive                      negative  \n",
       "2           positive        positive                      negative  \n",
       "3           negative        positive                      negative  \n",
       "4           negative        positive                      positive  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['Date','Header','Stock Price Change', 'Vader Sentiment', 'Logistic Regression Sentiment']\n",
    "df_summary = df[columns]\n",
    "df_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "IBM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
